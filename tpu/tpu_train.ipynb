{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "tpu_train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahvQZWQSfoEE",
        "colab_type": "code",
        "outputId": "4f3e304c-09d7-4cee-b2b6-a5b33eda2488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import auth\n",
        "\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.config.experimental_connect_to_host(cluster_resolver.get_master())\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
        "auth.authenticate_user()\n",
        "\n",
        "print('Tensorflow', tf.__version__)\n",
        "print('TPU address : {}'.format(TPU_WORKER))\n",
        "print('TPU cores : {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow 1.14.0\n",
            "TPU address : grpc://10.108.65.82:8470\n",
            "TPU cores : 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpWHjvU-foEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "    def imshow(image):\n",
        "        plt.figure(figsize=(12, 12))\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image)\n",
        "\n",
        "    def compute_anchor_dimensions(ratios=[0.5, 1, 2],\n",
        "                                  scales=[1, 1.25, 1.58],\n",
        "                                  areas=[32 * 32, 64 * 64, 128 * 128, 256 * 256, 512 * 512]):\n",
        "        anchor_shapes = {'P{}'.format(i): [] for i in range(3, 8)}\n",
        "        for area in areas:\n",
        "            for ratio in ratios:\n",
        "                a_h = np.sqrt(area / ratio)\n",
        "                a_w = area / a_h\n",
        "                for scale in scales:\n",
        "                    h = np.int32(scale * a_h)\n",
        "                    w = np.int32(scale * a_w)\n",
        "                    anchor_shapes['P{}'.format(\n",
        "                        int(np.log2(np.sqrt(area) // 4)))].append([w, h])\n",
        "            anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))] = np.array(\n",
        "                anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))])\n",
        "        return anchor_shapes\n",
        "\n",
        "    def get_anchors(input_shape=None, tensor=True):\n",
        "        anchor_dimensions = compute_anchor_dimensions()\n",
        "        anchors = []\n",
        "        for i in range(3, 8):\n",
        "            feature_name = 'P{}'.format(i)\n",
        "            stride = 2**i\n",
        "            feature_size = (input_shape) // stride\n",
        "\n",
        "            dims = anchor_dimensions[feature_name]\n",
        "            dims = dims[None, None, ...]\n",
        "            dims = np.tile(dims, reps=[feature_size, feature_size, 1, 1])\n",
        "\n",
        "            rx = (np.arange(feature_size) + 0.5) * (stride)\n",
        "            ry = (np.arange(feature_size) + 0.5) * (stride)\n",
        "            sx, sy = np.meshgrid(rx, ry)\n",
        "            cxy = np.stack([sx, sy], axis=-1)\n",
        "            cxy = cxy[:, :, None, :]\n",
        "            cxy = np.tile(cxy, reps=[1, 1, 9, 1])\n",
        "            anchors.append(np.reshape(\n",
        "                np.concatenate([cxy, dims], axis=-1), [-1, 4]))\n",
        "        anchors = np.concatenate(anchors, axis=0)\n",
        "        if tensor:\n",
        "            anchors = tf.constant(anchors, dtype=tf.float32)\n",
        "        return anchors\n",
        "\n",
        "    @tf.function()\n",
        "    def compute_iou(boxes1, boxes2):\n",
        "        boxes1 = tf.cast(boxes1, dtype=tf.float32)\n",
        "        boxes2 = tf.cast(boxes2, dtype=tf.float32)\n",
        "\n",
        "        boxes1_t = change_box_format(boxes1, return_format='x1y1x2y2')\n",
        "        boxes2_t = change_box_format(boxes2, return_format='x1y1x2y2')\n",
        "\n",
        "        lu = tf.maximum(boxes1_t[:, None, :2], boxes2_t[:, :2])\n",
        "        rd = tf.minimum(boxes1_t[:, None, 2:], boxes2_t[:, 2:])\n",
        "\n",
        "        intersection = tf.maximum(0.0, rd - lu)\n",
        "        inter_square = intersection[:, :, 0] * intersection[:, :, 1]\n",
        "\n",
        "        square1 = boxes1[:, 2] * boxes1[:, 3]\n",
        "        square2 = boxes2[:, 2] * boxes2[:, 3]\n",
        "\n",
        "        union_square = tf.maximum(\n",
        "            square1[:, None] + square2 - inter_square, 1e-10)\n",
        "        return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)\n",
        "\n",
        "    def change_box_format(boxes, return_format='xywh'):\n",
        "        boxes = tf.cast(boxes, dtype=tf.float32)\n",
        "        if return_format == 'xywh':\n",
        "\n",
        "            return tf.stack([(boxes[..., 2] + boxes[..., 0]) / 2.0,\n",
        "                             (boxes[..., 3] + boxes[..., 1]) / 2.0,\n",
        "                             boxes[..., 2] - boxes[..., 0],\n",
        "                             boxes[..., 3] - boxes[..., 1]], axis=-1)\n",
        "        elif return_format == 'x1y1x2y2':\n",
        "\n",
        "            return tf.stack([boxes[..., 0] - boxes[..., 2] / 2.0,\n",
        "                             boxes[..., 1] - boxes[..., 3] / 2.0,\n",
        "                             boxes[..., 0] + boxes[..., 2] / 2.0,\n",
        "                             boxes[..., 1] + boxes[..., 3] / 2.0], axis=-1)\n",
        "        return 'You should not be here'\n",
        "\n",
        "    def draw_bboxes(image, bbox_list):\n",
        "        image = image / 255.\n",
        "        h, w = image.shape.as_list()[:2]\n",
        "        bboxes = tf.cast(tf.stack([\n",
        "            bbox_list[:, 1] / h, bbox_list[:, 0] /\n",
        "            w, bbox_list[:, 3] / h, bbox_list[:, 2] / w\n",
        "        ], axis=-1), dtype=tf.float32)\n",
        "\n",
        "        colors = tf.random.uniform(maxval=1, shape=[bbox_list.shape[0], 3])\n",
        "        return tf.image.convert_image_dtype(tf.image.draw_bounding_boxes(image[None, ...],\n",
        "                                                                         bboxes[None, ...],\n",
        "                                                                         colors)[0, ...], dtype=tf.uint8)\n",
        "\n",
        "    def draw_boxes_cv2(image, bbox_list):\n",
        "        img = np.uint8(image).copy()\n",
        "        bbox_list = np.array(bbox_list, dtype=np.int32)\n",
        "        for box in bbox_list:\n",
        "            img = cv2.rectangle(img, (box[0], box[1]),\n",
        "                                (box[2], box[3]), [0, 0, 200], 3)\n",
        "        return img\n",
        "\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def encode_targets(label, input_shape=None):\n",
        "        \"\"\"We use the assignment rule from RPN.\n",
        "            Faster RCNN box coder follows the coding schema described below:\n",
        "                ty = (y - ya) / ha\n",
        "                tx = (x - xa) / wa\n",
        "                th = log(h / ha)\n",
        "                tw = log(w / wa)\n",
        "            where x, y, w, h denote the box's center coordinates, width and height\n",
        "            respectively. Similarly, xa, ya, wa, ha denote the anchor's center\n",
        "            coordinates, width and height. tx, ty, tw and th denote the\n",
        "            anchor-encoded center, width and height respectively.\n",
        "            The open-source implementation recommends using [10.0, 10.0, 5.0, 5.0] as\n",
        "            scale factors.\n",
        "            See http://arxiv.org/abs/1506.01497 for details. \n",
        "            Set achors with iou < 0.5 to 0 and\n",
        "            set achors with iou iou > 0.4 && < 0.5 to -1. Convert\n",
        "            regression targets into one-hot encoding (N, \n",
        "            in loss_fn and exclude background class in loss calculation.\n",
        "            Use [0, 0, 0, ... 0, n_classes] (all units set to zeros) to represent\n",
        "            background class.\n",
        "        \"\"\"\n",
        "        scale_factors = tf.constant([10.0, 10.0, 5.0, 5.0])\n",
        "        anchors = get_anchors(input_shape=input_shape, tensor=True)\n",
        "        gt_boxes = label[:, :4]\n",
        "        gt_boxes = change_box_format(gt_boxes, return_format='xywh')\n",
        "        gt_class_ids = label[:, 4]\n",
        "        ious = compute_iou(anchors, gt_boxes)\n",
        "\n",
        "        max_ious = tf.reduce_max(ious, axis=1)\n",
        "        max_ids = tf.argmax(ious, axis=1, output_type=tf.int32)\n",
        "\n",
        "        background_mask = max_ious > 0.5\n",
        "        ignore_mask = tf.logical_and(max_ious > 0.4, max_ious < 0.5)\n",
        "\n",
        "        selected_gt_boxes = tf.gather(gt_boxes, max_ids)\n",
        "        selected_gt_class_ids = 1. + tf.gather(gt_class_ids, max_ids)\n",
        "\n",
        "        selected_gt_class_ids = selected_gt_class_ids * \\\n",
        "            tf.cast(background_mask, dtype=tf.float32)\n",
        "        classification_targets = selected_gt_class_ids - tf.cast(\n",
        "            ignore_mask, dtype=tf.float32)\n",
        "        regression_targets = tf.stack([\n",
        "            (selected_gt_boxes[:, 0] - anchors[:, 0]) / anchors[:, 2],\n",
        "            (selected_gt_boxes[:, 1] - anchors[:, 1]) / anchors[:, 3],\n",
        "            tf.math.log(selected_gt_boxes[:, 2] / anchors[:, 2]),\n",
        "            tf.math.log(selected_gt_boxes[:, 3] / anchors[:, 3])\n",
        "        ], axis=-1)\n",
        "        regression_targets = regression_targets * scale_factors\n",
        "        reg_zeros = tf.zeros_like(regression_targets)\n",
        "        \n",
        "        '''dirty hack to filter inf occuring during box encoding\n",
        "        TODO - Handle objects with small area during tfrecord generation\n",
        "        '''\n",
        "        regression_targets = tf.where(tf.math.is_finite(regression_targets),\n",
        "                                                    regression_targets,\n",
        "                                                    reg_zeros)\n",
        "                                      \n",
        "        nan_losses_filter = tf.cast(tf.reduce_prod(tf.cast(tf.math.is_finite(regression_targets),\n",
        "                                                dtype=tf.float32), axis=-1), dtype=tf.bool)\n",
        "        background_mask = tf.logical_and(background_mask, nan_losses_filter)\n",
        "        ignore_mask = tf.logical_and(ignore_mask, nan_losses_filter)\n",
        "        return (tf.cast(classification_targets, dtype=tf.int32),\n",
        "                regression_targets,\n",
        "                background_mask,\n",
        "                ignore_mask)\n",
        "\n",
        "    def decode_targets(classification_outputs,\n",
        "                       regression_outputs,\n",
        "                       input_shape=512,\n",
        "                       classification_threshold=0.05,\n",
        "                       nms_threshold=0.5):\n",
        "        scale_factors = tf.constant([10.0, 10.0, 5.0, 5.0])\n",
        "        anchors = get_anchors(input_shape=input_shape, tensor=True)\n",
        "\n",
        "        class_ids = tf.argmax(classification_outputs, axis=-1)\n",
        "\n",
        "        confidence_scores = tf.reduce_max(\n",
        "            tf.nn.sigmoid(classification_outputs), axis=-1)\n",
        "        regression_outputs = regression_outputs / scale_factors\n",
        "        boxes = tf.concat([(regression_outputs[:, :2] * anchors[:, 2:] + anchors[:, :2]),\n",
        "                           tf.math.exp(\n",
        "                               regression_outputs[:, 2:]) * anchors[:, 2:]\n",
        "                           ], axis=-1)\n",
        "        boxes = change_box_format(boxes, return_format='x1y1x2y2')\n",
        "\n",
        "        nms_indices = tf.image.non_max_suppression(boxes,\n",
        "                                                   confidence_scores,\n",
        "                                                   score_threshold=classification_threshold,\n",
        "                                                   iou_threshold=nms_threshold,\n",
        "                                                   max_output_size=200)\n",
        "        final_class_ids = tf.gather(class_ids, nms_indices)\n",
        "        final_scores = tf.gather(confidence_scores, nms_indices)\n",
        "        final_boxes = tf.cast(tf.gather(boxes, nms_indices), dtype=tf.int32)\n",
        "\n",
        "        matched_anchors = tf.gather(anchors, tf.where(\n",
        "            confidence_scores > classification_threshold)[:, 0])\n",
        "        matched_anchors = tf.cast(change_box_format(matched_anchors, return_format='x1y1x2y2'),\n",
        "                                  dtype=tf.int32)\n",
        "        return final_boxes, final_class_ids, final_scores, matched_anchors\n",
        "\n",
        "    def conv_block(x,\n",
        "                   n_filters,\n",
        "                   size,\n",
        "                   strides=1,\n",
        "                   kernel_init='he_normal',\n",
        "                   bias_init='zeros',\n",
        "                   bn_activated=False, name=''):\n",
        "        x = tf.keras.layers.Conv2D(filters=n_filters,\n",
        "                                   kernel_size=size,\n",
        "                                   padding='same',\n",
        "                                   strides=strides,\n",
        "                                   kernel_initializer=kernel_init,\n",
        "                                   bias_initializer=bias_init,\n",
        "                                   name='conv_' + name if name else None)(x)\n",
        "        if bn_activated:\n",
        "            x = tf.keras.layers.BatchNormalization()(x)\n",
        "            x = tf.keras.layers.ReLU()(x)\n",
        "        return x\n",
        "\n",
        "    def Upsampling(tensor, scale=2):\n",
        "        dims = tensor.shape.as_list()[1:-1]\n",
        "        return tf.image.resize_bilinear(tensor, size=[dims[0] * scale, dims[1] * scale], align_corners=True)\n",
        "\n",
        "    def build_classification_subnet(n_classes=None, n_anchors=9, p=0.01):\n",
        "        input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
        "        x = input_layer\n",
        "        for i in range(4):\n",
        "            x = conv_block(\n",
        "                x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
        "            x = tf.keras.layers.ReLU()(x)\n",
        "        bias_init = -np.log((1 - p) / p)\n",
        "        output_layer = tf.keras.layers.Conv2D(filters=n_classes * n_anchors,\n",
        "                                              kernel_size=3,\n",
        "                                              padding='same',\n",
        "                                              kernel_initializer=tf.keras.initializers.RandomNormal(\n",
        "                                                  0.0, 0.01),\n",
        "                                              bias_initializer=tf.keras.initializers.Constant(\n",
        "                                                  value=bias_init),\n",
        "                                              activation=None)(x)\n",
        "        output_layer = tf.keras.layers.Reshape(\n",
        "            target_shape=[-1, n_classes])(output_layer)\n",
        "        return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='classification_subnet')\n",
        "\n",
        "    def build_regression_subnet(n_anchors=9):\n",
        "        input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
        "        x = input_layer\n",
        "        for i in range(4):\n",
        "            x = conv_block(\n",
        "                x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
        "            x = tf.keras.layers.ReLU()(x)\n",
        "        output_layer = tf.keras.layers.Conv2D(filters=4 * n_anchors,\n",
        "                                              kernel_size=3,\n",
        "                                              padding='same',\n",
        "                                              kernel_initializer=tf.keras.initializers.RandomNormal(\n",
        "                                                  0.0, 0.01),\n",
        "                                              bias_initializer=tf.keras.initializers.zeros(),\n",
        "                                              activation=None)(x)\n",
        "        output_layer = tf.keras.layers.Reshape(\n",
        "            target_shape=[-1, 4])(output_layer)\n",
        "        return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='regression_subnet')\n",
        "\n",
        "    class LossV2():\n",
        "        def __init__(self, n_classes=None):\n",
        "            self.num_classes = n_classes\n",
        "            self.smooth_l1 = tf.compat.v2.losses.Huber(delta=0.11, reduction='none')\n",
        "\n",
        "        def focal_loss(self, y_true, y_pred, alpha=0.25, gamma=2):\n",
        "            y_true = tf.one_hot(\n",
        "                tf.cast(y_true, dtype=tf.int32), depth=self.num_classes + 1)\n",
        "            y_true = y_true[:, :, 1:]\n",
        "            y_pred_ = tf.sigmoid(y_pred)\n",
        "\n",
        "            at = alpha * y_true + (1 - y_true) * (1 - alpha)\n",
        "            pt = y_true * y_pred_ + (1 - y_true) * (1 - y_pred_)\n",
        "            f_loss = at * tf.pow(1 - pt, gamma) * tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
        "\n",
        "            return f_loss\n",
        "\n",
        "        def smooth_l1_(self, y_true, y_pred, sigma=3.0):\n",
        "            y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
        "            sigma = tf.cast(sigma, dtype=y_pred.dtype)\n",
        "            x = y_true - y_pred\n",
        "            abs_x = tf.abs(x)\n",
        "            sigma_squared = tf.square(sigma)\n",
        "            quadratic = 0.5 * tf.square(sigma * x)\n",
        "            linear = abs_x - (0.5 / sigma_squared)\n",
        "            smooth_l1_loss = tf.where(\n",
        "                tf.less_equal(abs_x, 1. / sigma_squared), quadratic, linear)\n",
        "            return smooth_l1_loss\n",
        "\n",
        "        def __call__(self, tensor):\n",
        "            classification_targets = tensor[0]\n",
        "            classification_predictions = tensor[1]\n",
        "            regression_targets = tensor[2]\n",
        "            regression_predictions = tensor[3]\n",
        "            background_mask = tensor[4]\n",
        "            ignore_mask = tensor[5]\n",
        "\n",
        "            background_mask = tf.cast(\n",
        "                background_mask, dtype=tf.bool, name='bg_cast')\n",
        "            ignore_mask = tf.cast(ignore_mask, dtype=tf.bool, name='ig_cast')\n",
        "\n",
        "            num_positive_detections = tf.maximum(tf.reduce_sum(\n",
        "                tf.cast(background_mask, dtype=tf.float32), axis=-1), 1.0)\n",
        "\n",
        "            positive_classification_mask = tf.expand_dims(\n",
        "                tf.logical_not(ignore_mask), axis=-1)\n",
        "            positive_classification_mask = tf.tile(\n",
        "                positive_classification_mask, multiples=[1, 1, self.num_classes])\n",
        "\n",
        "            positive_regression_mask = tf.expand_dims(background_mask, axis=-1)\n",
        "            positive_regression_mask = tf.tile(\n",
        "                positive_regression_mask, multiples=[1, 1, 4])\n",
        "\n",
        "            Lcls = self.focal_loss(classification_targets,\n",
        "                                   classification_predictions)\n",
        "            Lreg = self.smooth_l1(regression_targets, regression_predictions)\n",
        "            Lcls = Lcls * \\\n",
        "                tf.cast(positive_classification_mask, dtype=tf.float32)\n",
        "            Lreg = Lreg * tf.cast(positive_regression_mask, dtype=tf.float32)\n",
        "\n",
        "            Lcls = tf.reduce_sum(\n",
        "                Lcls, axis=[1, 2]) / num_positive_detections\n",
        "            Lreg = tf.reduce_sum(\n",
        "                Lreg, axis=[1, 2]) / num_positive_detections\n",
        "\n",
        "            Lcls = tf.reduce_mean(Lcls)\n",
        "            Lreg = tf.reduce_mean(Lreg)\n",
        "            return Lreg, Lcls, tf.reduce_mean(num_positive_detections)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_aGcRv6foEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_map = {value: idx for idx, value in enumerate(['bus',\n",
        "                                                     'traffic light',\n",
        "                                                     'traffic sign',\n",
        "                                                     'person',\n",
        "                                                     'bike',\n",
        "                                                     'truck',\n",
        "                                                     'motor',\n",
        "                                                     'car',\n",
        "                                                     'train',\n",
        "                                                     'rider'])}\n",
        "\n",
        "INPUT_SHAPE = 640\n",
        "BATCH_SIZE = 64\n",
        "N_CLASSES = len(class_map)\n",
        "EPOCHS = 200\n",
        "training_steps = 70000 // BATCH_SIZE\n",
        "val_steps = 10000 // BATCH_SIZE\n",
        "LR = 8 * 1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqxKuvBefoEL",
        "colab_type": "code",
        "outputId": "9e99fab2-63b8-43e6-e52a-0180e6c51c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "with strategy.scope():\n",
        "    feature_description = {\n",
        "        'image' : tf.io.FixedLenFeature([], tf.string),\n",
        "        'xmins': tf.io.VarLenFeature(tf.float32),\n",
        "        'ymins': tf.io.VarLenFeature(tf.float32),\n",
        "        'xmaxs': tf.io.VarLenFeature(tf.float32),\n",
        "        'ymaxs': tf.io.VarLenFeature(tf.float32),\n",
        "        'labels': tf.io.VarLenFeature(tf.float32)\n",
        "    }\n",
        "\n",
        "    @tf.function\n",
        "    def parse_example(example_proto):\n",
        "        parsed_example = tf.io.parse_single_example(example_proto, feature_description)\n",
        "        image = tf.image.decode_jpeg(parsed_example['image'], channels=3)\n",
        "        bboxes = tf.stack([\n",
        "            tf.sparse_tensor_to_dense(parsed_example['xmins']),\n",
        "            tf.sparse_tensor_to_dense(parsed_example['ymins']),\n",
        "            tf.sparse_tensor_to_dense(parsed_example['xmaxs']),\n",
        "            tf.sparse_tensor_to_dense(parsed_example['ymaxs'])\n",
        "        ], axis=-1)\n",
        "        class_ids = tf.reshape(tf.sparse_tensor_to_dense(parsed_example['labels']), [-1, 1])\n",
        "        return image, bboxes, class_ids\n",
        "    \n",
        "    \n",
        "    \n",
        "    @tf.function\n",
        "    def random_image_augmentation(img):\n",
        "        img = tf.image.random_brightness(img, max_delta=50.)\n",
        "        img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
        "        img = tf.image.random_hue(img, max_delta=0.2)\n",
        "        img = tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
        "        img = tf.clip_by_value(img, 0, 255)\n",
        "        return img\n",
        "    \n",
        "\n",
        "    \n",
        "    @tf.function\n",
        "    def flip_data(image, boxes, w):\n",
        "        if tf.random.uniform(()) > 0.5:\n",
        "            image = tf.image.flip_left_right(image)\n",
        "            boxes = tf.stack([\n",
        "                w - boxes[:, 2],\n",
        "                boxes[:, 1],\n",
        "                w - boxes[:, 0],\n",
        "                boxes[:, 3]\n",
        "            ], axis=-1)\n",
        "        return image, boxes\n",
        "\n",
        "    def load_data(input_shape):\n",
        "        h, w = input_shape, input_shape\n",
        "\n",
        "        @tf.function\n",
        "        def load_data_(example_proto, input_shape=input_shape):\n",
        "            image, boxes_, class_ids = parse_example(example_proto)\n",
        "            image = tf.image.resize(image, size=[h, w])\n",
        "            boxes = tf.stack([\n",
        "                tf.clip_by_value(boxes_[:, 0] * w, 0, w),\n",
        "                tf.clip_by_value(boxes_[:, 1] * h, 0, h),\n",
        "                tf.clip_by_value(boxes_[:, 2] * w, 0, w),\n",
        "                tf.clip_by_value(boxes_[:, 3] * h, 0, h)\n",
        "            ], axis=-1)\n",
        "            image, boxes = flip_data(image, boxes, w)\n",
        "            image = random_image_augmentation(image)\n",
        "            image = image[:, :, ::-1] - tf.constant([103.939, 116.779, 123.68])\n",
        "            label = tf.concat([boxes, class_ids], axis=-1)\n",
        "            cls_targets, reg_targets, bg, ig = encode_targets(\n",
        "                label, input_shape=input_shape)\n",
        "            bg = tf.cast(bg, dtype=tf.float32)\n",
        "            ig = tf.cast(ig, dtype=tf.float32)\n",
        "            cls_targets = tf.cast(cls_targets, dtype=tf.float32)\n",
        "            return (image, cls_targets, reg_targets, bg, ig), (tf.ones((1, )), tf.ones((1, )))\n",
        "        return load_data_\n",
        "\n",
        "    train_files = tf.data.Dataset.list_files(\n",
        "        'gs://srihari-datasets/BDD100k/train*')\n",
        "    train_dataset = train_files.interleave(tf.data.TFRecordDataset,\n",
        "                                           cycle_length=16,\n",
        "                                           block_length=16,\n",
        "                                           num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    train_dataset = train_dataset.map(\n",
        "        load_data(INPUT_SHAPE), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    train_dataset = train_dataset.batch(\n",
        "        BATCH_SIZE, drop_remainder=True).repeat()\n",
        "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    val_files = tf.data.Dataset.list_files(\n",
        "        'gs://srihari-datasets/BDD100k/validation*')\n",
        "    val_dataset = val_files.interleave(tf.data.TFRecordDataset,\n",
        "                                       cycle_length=16,\n",
        "                                       block_length=16,\n",
        "                                       num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    val_dataset = val_dataset.map(\n",
        "        load_data(INPUT_SHAPE), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
        "    val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0905 11:45:58.493444 140292060342144 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "W0905 11:46:00.516666 140292060342144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPEaKjKLpGqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i = 0\n",
        "# for batch in train_dataset.take(1):\n",
        "#     break\n",
        "# image, cls_targets, reg_targets, _, _ = batch[0]\n",
        "# classification_outputs = tf.one_hot(tf.cast(cls_targets[i], dtype=tf.int32), depth=N_CLASSES + 1)[:, 1:]\n",
        "# regression_outputs = reg_targets[i]\n",
        "# image = image[i]\n",
        "# scale_factors = tf.constant([5.0, 5.0, 5.0, 5.0])\n",
        "# anchors = get_anchors(input_shape=INPUT_SHAPE, tensor=True)\n",
        "# class_ids = tf.argmax(classification_outputs, axis=-1)\n",
        "# confidence_scores = tf.reduce_max(classification_outputs, axis=-1)\n",
        "# regression_outputs = regression_outputs / scale_factors\n",
        "# boxes = tf.concat([(regression_outputs[:, :2] * anchors[:, 2:] + anchors[:, :2]),\n",
        "#                    tf.math.exp(regression_outputs[:, 2:]) * anchors[:, 2:]\n",
        "#                    ], axis=-1)\n",
        "# boxes = change_box_format(boxes, return_format='x1y1x2y2')\n",
        "\n",
        "# nms_indices = tf.image.non_max_suppression(boxes,\n",
        "#                                            confidence_scores,\n",
        "#                                            score_threshold=0.05,\n",
        "#                                            iou_threshold=0.5,\n",
        "#                                            max_output_size=200)\n",
        "# final_class_ids = tf.gather(class_ids, nms_indices)\n",
        "# final_scores = tf.gather(confidence_scores, nms_indices)\n",
        "# final_boxes = tf.cast(tf.gather(boxes, nms_indices), dtype=tf.int32)\n",
        "\n",
        "# matched_anchors = tf.gather(anchors, tf.where(confidence_scores > 0.05)[:, 0])\n",
        "# matched_anchors = tf.cast(change_box_format(matched_anchors, return_format='x1y1x2y2'),\n",
        "#                           dtype=tf.int32)\n",
        "# img = draw_boxes_cv2(image, boxes)\n",
        "# imshow(img)\n",
        "# print(final_boxes.numpy())\n",
        "# print(final_class_ids.numpy())\n",
        "# print(final_scores.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5n59juRfoEO",
        "colab_type": "code",
        "outputId": "5daea3bf-95a8-4178-b51f-40afc3f37813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "with strategy.scope():\n",
        "    def RetinaNet(input_shape=None, n_classes=None, training=False):\n",
        "        H = W = input_shape\n",
        "        num_anchors = get_anchors(input_shape=H).shape[0]\n",
        "        loss_fn = LossV2(n_classes=n_classes)\n",
        "\n",
        "        base_model = tf.keras.applications.ResNet50(\n",
        "            input_shape=[H, W, 3], weights='imagenet', include_top=False)\n",
        "        \n",
        "        resnet_block_output_names = [\n",
        "            'activation_21', 'activation_39', 'activation_48']\n",
        "\n",
        "        resnet_block_outputs = {'C{}'.format(idx + 3): base_model.get_layer(\n",
        "            layer).output for idx, layer in enumerate(resnet_block_output_names)}\n",
        "        resnet_block_outputs = {level: conv_block(\n",
        "            tensor, 256, 1, name=level + '_1x1') for level, tensor in resnet_block_outputs.items()}\n",
        "\n",
        "        P5 = resnet_block_outputs['C5']\n",
        "        P6 = conv_block(base_model.get_layer(\n",
        "            'activation_48').output, 256, 3, strides=2, name='P6')\n",
        "        P6_relu = tf.keras.layers.ReLU(name='P6')(P6)\n",
        "        P7 = conv_block(P6_relu, 256, 3, strides=2, name='P7')\n",
        "        M4 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2}, name='P5_UP')(\n",
        "            P5), resnet_block_outputs['C4']], name='P4_merge')\n",
        "        M3 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2}, name='P4_UP')(\n",
        "            M4), resnet_block_outputs['C3']], name='P3_merge')\n",
        "        P4 = conv_block(M4, 256, 3, name='P4')\n",
        "        P3 = conv_block(M3, 256, 3, name='P3')\n",
        "#         pyrammid_features = [P7, P6, P5, P4, P3]\n",
        "        pyrammid_features = [P3, P4, P5, P6, P7]\n",
        "\n",
        "\n",
        "        classification_subnet = build_classification_subnet(\n",
        "            n_classes=n_classes)\n",
        "        regression_subnet = build_regression_subnet()\n",
        "\n",
        "        classification_outputs = [classification_subnet(\n",
        "            level) for level in pyrammid_features]\n",
        "        regression_outputs = [regression_subnet(\n",
        "            level) for level in pyrammid_features]\n",
        "\n",
        "        classification_head = tf.keras.layers.concatenate(\n",
        "            classification_outputs, axis=1, name='classification_head')\n",
        "        regression_head = tf.keras.layers.concatenate(\n",
        "            regression_outputs, axis=1, name='regression_head')\n",
        "\n",
        "        image_input = base_model.input\n",
        "        classification_targets = tf.keras.layers.Input(shape=[num_anchors])\n",
        "        regression_targets = tf.keras.layers.Input(shape=[num_anchors, 4])\n",
        "        background_mask = tf.keras.layers.Input(shape=[num_anchors])\n",
        "        ignore_mask = tf.keras.layers.Input(shape=[num_anchors])\n",
        "\n",
        "        Lreg, Lcls, _ = tf.keras.layers.Lambda(loss_fn)([classification_targets,\n",
        "                                                         classification_head,\n",
        "                                                         regression_targets,\n",
        "                                                         regression_head,\n",
        "                                                         background_mask,\n",
        "                                                         ignore_mask])\n",
        "\n",
        "        Lreg = tf.keras.layers.Lambda(\n",
        "            lambda x: tf.reshape(x, [-1, 1]), name='box')(Lreg)\n",
        "        Lcls = tf.keras.layers.Lambda(\n",
        "            lambda x: tf.reshape(x, [-1, 1]), name='focal')(Lcls)\n",
        "\n",
        "        if training:\n",
        "            _inputs = [image_input, classification_targets,\n",
        "                       regression_targets, background_mask, ignore_mask]\n",
        "            _outputs = [Lreg, Lcls]\n",
        "        else:\n",
        "            _inputs = [image_input]\n",
        "            _outputs = [classification_head, regression_head]\n",
        "        model =  tf.keras.Model(inputs=_inputs, outputs=_outputs, name='RetinaNet')\n",
        "        return model\n",
        "    \n",
        "\n",
        "    model = RetinaNet(input_shape=INPUT_SHAPE,\n",
        "                      n_classes=N_CLASSES, training=True)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=LR, clipnorm=0.001)\n",
        "\n",
        "    loss_dict = {\n",
        "        'box': lambda x, y: y,\n",
        "        'focal': lambda x, y: y\n",
        "    }\n",
        "    callback_list = [\n",
        "        tf.keras.callbacks.TensorBoard(\n",
        "            log_dir='gs://srihari-datasets/retinanet/logs', update_freq='epoch'),\n",
        "        tf.keras.callbacks.ModelCheckpoint('gs://srihari-datasets/retinanet/weights',\n",
        "                                           save_weights_only=True,\n",
        "                                           save_best_only=True,\n",
        "                                           monitor='loss',\n",
        "                                           verbose=1)\n",
        "    ]\n",
        "    model.compile(optimizer=optimizer, loss=loss_dict)\n",
        "#     model.load_weights('gs://srihari-datasets/retinanet/imagenet_pretrained_weights/ckpt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "W0905 11:46:47.436550 140292060342144 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtTxJvOYRIq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with strategy.scope():\n",
        "#     model.load_weights('gs://srihari-datasets/retinanet/weights')\n",
        "#     K.get_session().run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
        "#     model.save_weights('gs://srihari-datasets/retinanet/imagenet_pretrained_weights/ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOOUTDasSu02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "34cc2826-8847-4ec0-c1ee-2fc421a1acdd"
      },
      "source": [
        "model.fit(train_dataset,\n",
        "          epochs=EPOCHS,\n",
        "          steps_per_epoch=training_steps,\n",
        "          validation_data=val_dataset,\n",
        "          validation_steps=val_steps,\n",
        "          validation_freq=5,\n",
        "          callbacks=callback_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0905 11:49:37.125901 140292060342144 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py:411: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "   2/1093 [..............................] - ETA: 7:01:25 - loss: 25.6372 - box_loss: 0.5153 - focal_loss: 25.1219"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0905 11:50:23.478752 140292060342144 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (1.511015). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1092/1093 [============================>.] - ETA: 0s - loss: 1.0549 - box_loss: 0.2759 - focal_loss: 0.7791\n",
            "Epoch 00001: loss improved from inf to 1.05443, saving model to gs://srihari-datasets/retinanet/weights\n",
            "1093/1093 [==============================] - 843s 772ms/step - loss: 1.0544 - box_loss: 0.2758 - focal_loss: 0.7786\n",
            "Epoch 2/200\n",
            "1092/1093 [============================>.] - ETA: 0s - loss: 0.8470 - box_loss: 0.1876 - focal_loss: 0.6595\n",
            "Epoch 00002: loss improved from 1.05443 to 0.84667, saving model to gs://srihari-datasets/retinanet/weights\n",
            "1093/1093 [==============================] - 787s 720ms/step - loss: 0.8467 - box_loss: 0.1876 - focal_loss: 0.6591\n",
            "Epoch 3/200\n",
            "1092/1093 [============================>.] - ETA: 0s - loss: 0.4151 - box_loss: 0.1666 - focal_loss: 0.2485\n",
            "Epoch 00003: loss improved from 0.84667 to 0.41506, saving model to gs://srihari-datasets/retinanet/weights\n",
            "1093/1093 [==============================] - 788s 721ms/step - loss: 0.4151 - box_loss: 0.1666 - focal_loss: 0.2485\n",
            "Epoch 4/200\n",
            "1092/1093 [============================>.] - ETA: 0s - loss: 0.3810 - box_loss: 0.1561 - focal_loss: 0.2249\n",
            "Epoch 00004: loss improved from 0.41506 to 0.38101, saving model to gs://srihari-datasets/retinanet/weights\n",
            "1093/1093 [==============================] - 788s 721ms/step - loss: 0.3810 - box_loss: 0.1561 - focal_loss: 0.2249\n",
            "Epoch 5/200\n",
            "156/156 [==============================] - 129s 827ms/step\n",
            "156/156 [==============================] - 129s 827ms/step\n",
            "\n",
            "Epoch 00005: loss improved from 0.38101 to 0.35861, saving model to gs://srihari-datasets/retinanet/weights\n",
            "1093/1093 [==============================] - 948s 867ms/step - loss: 0.3586 - box_loss: 0.1494 - focal_loss: 0.2092 - val_loss: 0.4017 - val_box_loss: 0.1623 - val_focal_loss: 0.2395\n",
            "Epoch 6/200\n",
            "1092/1093 [============================>.] - ETA: 0s - loss: 0.3410 - box_loss: 0.1442 - focal_loss: 0.1967\n",
            "Epoch 00006: loss improved from 0.35861 to 0.34091, saving model to gs://srihari-datasets/retinanet/weights\n",
            "1093/1093 [==============================] - 789s 722ms/step - loss: 0.3409 - box_loss: 0.1442 - focal_loss: 0.1967\n",
            "Epoch 7/200\n",
            "1092/1093 [============================>.] - ETA: 0s - loss: 0.3290 - box_loss: 0.1409 - focal_loss: 0.1880\n",
            "Epoch 00007: loss improved from 0.34091 to 0.32897, saving model to gs://srihari-datasets/retinanet/weights\n",
            "1093/1093 [==============================] - 790s 723ms/step - loss: 0.3290 - box_loss: 0.1409 - focal_loss: 0.1880\n",
            "Epoch 8/200\n",
            "1092/1093 [============================>.] - ETA: 0s - loss: 0.3177 - box_loss: 0.1380 - focal_loss: 0.1798\n",
            "Epoch 00008: loss improved from 0.32897 to 0.31774, saving model to gs://srihari-datasets/retinanet/weights\n",
            "1093/1093 [==============================] - 790s 723ms/step - loss: 0.3177 - box_loss: 0.1380 - focal_loss: 0.1798\n",
            "Epoch 9/200\n",
            " 476/1093 [============>.................] - ETA: 7:17 - loss: 0.3105 - box_loss: 0.1362 - focal_loss: 0.1743"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9RH7PyZH3my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}