{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow 1.14.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.io import imread, imsave\n",
    "from tqdm import tqdm_notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print('Tensorflow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "\n",
    "def compute_anchor_dimensions(ratios=[0.5, 1, 2],\n",
    "                              scales=[1, 1.25, 1.58],\n",
    "                              areas=[32 * 32, 64 * 64, 128 * 128, 256 * 256, 512 * 512]):\n",
    "    anchor_shapes = {'P{}'.format(i): [] for i in range(3, 8)}\n",
    "    for area in areas:\n",
    "        for ratio in ratios:\n",
    "            a_h = np.sqrt(area / ratio)\n",
    "            a_w = area / a_h\n",
    "            for scale in scales:\n",
    "                h = np.int32(scale * a_h)\n",
    "                w = np.int32(scale * a_w)\n",
    "                anchor_shapes['P{}'.format(\n",
    "                    int(np.log2(np.sqrt(area) // 4)))].append([w, h])\n",
    "        anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))] = np.array(\n",
    "            anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))])\n",
    "    return anchor_shapes\n",
    "\n",
    "def get_anchors(input_shape=None, tensor=True):\n",
    "    anchor_dimensions = compute_anchor_dimensions()\n",
    "    anchors = []\n",
    "    for i in range(3, 8):\n",
    "        feature_name = 'P{}'.format(i)\n",
    "        stride = 2**i\n",
    "        feature_size = (input_shape) // stride\n",
    "\n",
    "        dims = anchor_dimensions[feature_name]\n",
    "        dims = dims[None, None, ...]\n",
    "        dims = np.tile(dims, reps=[feature_size, feature_size, 1, 1])\n",
    "\n",
    "        rx = (np.arange(feature_size) + 0.5) * (stride)\n",
    "        ry = (np.arange(feature_size) + 0.5) * (stride)\n",
    "        sx, sy = np.meshgrid(rx, ry)\n",
    "        cxy = np.stack([sx, sy], axis=-1)\n",
    "        cxy = cxy[:, :, None, :]\n",
    "        cxy = np.tile(cxy, reps=[1, 1, 9, 1])\n",
    "        anchors.append(np.reshape(\n",
    "            np.concatenate([cxy, dims], axis=-1), [-1, 4]))\n",
    "    anchors = np.concatenate(anchors, axis=0)\n",
    "    if tensor:\n",
    "        anchors = tf.constant(anchors, dtype=tf.float32)\n",
    "    return anchors\n",
    "\n",
    "def change_box_format(boxes, return_format='xywh'):\n",
    "    boxes = tf.cast(boxes, dtype=tf.float32)\n",
    "    if return_format == 'xywh':\n",
    "\n",
    "        return tf.stack([(boxes[..., 2] + boxes[..., 0]) / 2.0,\n",
    "                         (boxes[..., 3] + boxes[..., 1]) / 2.0,\n",
    "                         boxes[..., 2] - boxes[..., 0],\n",
    "                         boxes[..., 3] - boxes[..., 1]], axis=-1)\n",
    "    elif return_format == 'x1y1x2y2':\n",
    "\n",
    "        return tf.stack([boxes[..., 0] - boxes[..., 2] / 2.0,\n",
    "                         boxes[..., 1] - boxes[..., 3] / 2.0,\n",
    "                         boxes[..., 0] + boxes[..., 2] / 2.0,\n",
    "                         boxes[..., 1] + boxes[..., 3] / 2.0], axis=-1)\n",
    "    return 'You should not be here'\n",
    "\n",
    "def draw_bboxes(image, bbox_list):\n",
    "    image = image / 255.\n",
    "    h, w = image.shape.as_list()[:2]\n",
    "    bboxes = tf.cast(tf.stack([\n",
    "        bbox_list[:, 1] / h, bbox_list[:, 0] /\n",
    "        w, bbox_list[:, 3] / h, bbox_list[:, 2] / w\n",
    "    ], axis=-1), dtype=tf.float32)\n",
    "\n",
    "    colors = tf.random.uniform(maxval=1, shape=[bbox_list.shape[0], 3])\n",
    "    return tf.image.convert_image_dtype(tf.image.draw_bounding_boxes(image[None, ...],\n",
    "                                                                     bboxes[None, ...],\n",
    "                                                                     colors)[0, ...], dtype=tf.uint8)\n",
    "\n",
    "def draw_boxes_cv2(image, bbox_list, class_ids, scores, model_input_shape):\n",
    "    img = np.uint8(image).copy()\n",
    "    bbox_list = np.array(bbox_list, dtype=np.int32)\n",
    "    h, w = img.shape[:2]\n",
    "    h_scale, w_scale = h / model_input_shape, w / model_input_shape\n",
    "    bbox_list = np.int32(bbox_list * np.array([w_scale, h_scale] * 2))\n",
    "    for box, cls_, score in zip(bbox_list, class_ids, scores):\n",
    "        text = classes[cls_] + '' + str(np.round(score, 2))\n",
    "        text_orig = (box[0]+2, box[1]+9)\n",
    "        text_bg_xy1 = (box[0], box[1])\n",
    "        text_bg_xy2 = (box[0]+60, box[1]+18)\n",
    "        img = cv2.rectangle(img, text_bg_xy1,\n",
    "                            text_bg_xy2, [255, 252, 193], -1)\n",
    "        img = cv2.putText(img, text, text_orig, cv2.FONT_HERSHEY_COMPLEX_SMALL, .5, [0, 0, 0], 3, lineType=cv2.LINE_AA)\n",
    "        img = cv2.putText(img, text, text_orig, cv2.FONT_HERSHEY_COMPLEX_SMALL, .5, [255, 255, 255], 1, lineType=cv2.LINE_AA)\n",
    "        img = cv2.rectangle(img, (box[0], box[1]),\n",
    "                            (box[2], box[3]), [30, 15, 200], 1)\n",
    "    return img\n",
    "\n",
    "def decode_targets(classification_outputs,\n",
    "                   regression_outputs,\n",
    "                   input_shape=512,\n",
    "                   classification_threshold=0.05,\n",
    "                   nms_threshold=0.5):\n",
    "    scale_factors = tf.constant([10.0, 10.0, 5.0, 5.0])\n",
    "    anchors = get_anchors(input_shape=input_shape, tensor=True)\n",
    "\n",
    "    class_ids = tf.argmax(classification_outputs, axis=-1)\n",
    "\n",
    "    confidence_scores = tf.reduce_max(\n",
    "        tf.nn.sigmoid(classification_outputs), axis=-1)\n",
    "    regression_outputs = regression_outputs / scale_factors\n",
    "    boxes = tf.concat([(regression_outputs[:, :2] * anchors[:, 2:] + anchors[:, :2]),\n",
    "                       tf.math.exp(\n",
    "                           regression_outputs[:, 2:]) * anchors[:, 2:]\n",
    "                       ], axis=-1)\n",
    "    boxes = change_box_format(boxes, return_format='x1y1x2y2')\n",
    "\n",
    "    nms_indices = tf.image.non_max_suppression(boxes,\n",
    "                                               confidence_scores,\n",
    "                                               score_threshold=classification_threshold,\n",
    "                                               iou_threshold=nms_threshold,\n",
    "                                               max_output_size=100)\n",
    "    final_class_ids = tf.gather(class_ids, nms_indices)\n",
    "    final_scores = tf.gather(confidence_scores, nms_indices)\n",
    "    final_boxes = tf.cast(tf.gather(boxes, nms_indices), dtype=tf.int32)\n",
    "\n",
    "    matched_anchors = tf.gather(anchors, tf.where(\n",
    "        confidence_scores > classification_threshold)[:, 0])\n",
    "    matched_anchors = tf.cast(change_box_format(matched_anchors, return_format='x1y1x2y2'),\n",
    "                              dtype=tf.int32)\n",
    "    return final_boxes, final_class_ids, final_scores, matched_anchors\n",
    "\n",
    "def conv_block(x,\n",
    "               n_filters,\n",
    "               size,\n",
    "               strides=1,\n",
    "               kernel_init='he_normal',\n",
    "               bias_init='zeros',\n",
    "               bn_activated=False, name=''):\n",
    "    x = tf.keras.layers.Conv2D(filters=n_filters,\n",
    "                               kernel_size=size,\n",
    "                               padding='same',\n",
    "                               strides=strides,\n",
    "                               kernel_initializer=kernel_init,\n",
    "                               bias_initializer=bias_init,\n",
    "                               name='conv_' + name if name else None)(x)\n",
    "    if bn_activated:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def Upsampling(tensor, scale=2):\n",
    "    dims = tensor.shape.as_list()[1:-1]\n",
    "    return tf.image.resize_bilinear(tensor, size=[dims[0] * scale, dims[1] * scale], align_corners=True)\n",
    "\n",
    "def build_classification_subnet(n_classes=None, n_anchors=9, p=0.01):\n",
    "    input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
    "    x = input_layer\n",
    "    for i in range(4):\n",
    "        x = conv_block(\n",
    "            x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    bias_init = -np.log((1 - p) / p)\n",
    "    output_layer = tf.keras.layers.Conv2D(filters=n_classes * n_anchors,\n",
    "                                          kernel_size=3,\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "                                              0.0, 0.01),\n",
    "                                          bias_initializer=tf.keras.initializers.Constant(\n",
    "                                              value=bias_init),\n",
    "                                          activation=None)(x)\n",
    "    output_layer = tf.keras.layers.Reshape(\n",
    "        target_shape=[-1, n_classes])(output_layer)\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='classification_subnet')\n",
    "\n",
    "def build_regression_subnet(n_anchors=9):\n",
    "    input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
    "    x = input_layer\n",
    "    for i in range(4):\n",
    "        x = conv_block(\n",
    "            x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    output_layer = tf.keras.layers.Conv2D(filters=4 * n_anchors,\n",
    "                                          kernel_size=3,\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "                                              0.0, 0.01),\n",
    "                                          bias_initializer=tf.keras.initializers.zeros(),\n",
    "                                          activation=None)(x)\n",
    "    output_layer = tf.keras.layers.Reshape(\n",
    "        target_shape=[-1, 4])(output_layer)\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='regression_subnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {value: idx for idx, value in enumerate(['bus',\n",
    "                                                     'traffic light',\n",
    "                                                     'traffic sign',\n",
    "                                                     'person',\n",
    "                                                     'bike',\n",
    "                                                     'truck',\n",
    "                                                     'motor',\n",
    "                                                     'car',\n",
    "                                                     'train',\n",
    "                                                     'rider'])}\n",
    "\n",
    "INPUT_SHAPE = 640\n",
    "BATCH_SIZE = 1\n",
    "N_CLASSES = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srihari/tf2.0/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0905 23:04:11.023045 4726576576 deprecation.py:323] From /Users/srihari/tf2.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x146ffd9e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LossV2():\n",
    "    def __init__(self, batch_size=None, n_classes=None):\n",
    "        self.num_classes = n_classes\n",
    "        self.global_batch_size = batch_size\n",
    "        self.smooth_l1 = tf.compat.v2.losses.Huber(delta=0.11, reduction='none')\n",
    "\n",
    "    def focal_loss(self, y_true, y_pred, alpha=0.25, gamma=2):\n",
    "        y_true = tf.one_hot(\n",
    "            tf.cast(y_true, dtype=tf.int32), depth=self.num_classes + 1)\n",
    "        y_true = y_true[:, :, 1:]\n",
    "        y_pred_ = tf.sigmoid(y_pred)\n",
    "\n",
    "        at = alpha * y_true + (1 - y_true) * (1 - alpha)\n",
    "        pt = y_true * y_pred_ + (1 - y_true) * (1 - y_pred_)\n",
    "        f_loss = at * tf.pow(1 - pt, gamma) * tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "\n",
    "        return f_loss\n",
    "\n",
    "    def smooth_l1_(self, y_true, y_pred, sigma=3.0):\n",
    "        y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "        sigma = tf.cast(sigma, dtype=y_pred.dtype)\n",
    "        x = y_true - y_pred\n",
    "        abs_x = tf.abs(x)\n",
    "        sigma_squared = tf.square(sigma)\n",
    "        quadratic = 0.5 * tf.square(sigma * x)\n",
    "        linear = abs_x - (0.5 / sigma_squared)\n",
    "        smooth_l1_loss = tf.where(\n",
    "            tf.less_equal(abs_x, 1. / sigma_squared), quadratic, linear)\n",
    "        return smooth_l1_loss\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        classification_targets = tensor[0]\n",
    "        classification_predictions = tensor[1]\n",
    "        regression_targets = tensor[2]\n",
    "        regression_predictions = tensor[3]\n",
    "        background_mask = tensor[4]\n",
    "        ignore_mask = tensor[5]\n",
    "\n",
    "        background_mask = tf.cast(\n",
    "            background_mask, dtype=tf.bool, name='bg_cast')\n",
    "        ignore_mask = tf.cast(ignore_mask, dtype=tf.bool, name='ig_cast')\n",
    "\n",
    "        num_positive_detections = tf.maximum(tf.reduce_sum(\n",
    "            tf.cast(background_mask, dtype=tf.float32), axis=-1), 1.0)\n",
    "\n",
    "        positive_classification_mask = tf.expand_dims(\n",
    "            tf.logical_not(ignore_mask), axis=-1)\n",
    "        positive_classification_mask = tf.tile(\n",
    "            positive_classification_mask, multiples=[1, 1, self.num_classes])\n",
    "\n",
    "        positive_regression_mask = tf.expand_dims(background_mask, axis=-1)\n",
    "        positive_regression_mask = tf.tile(\n",
    "            positive_regression_mask, multiples=[1, 1, 4])\n",
    "\n",
    "        Lcls = self.focal_loss(classification_targets,\n",
    "                               classification_predictions)\n",
    "        Lreg = self.smooth_l1(regression_targets, regression_predictions)\n",
    "        Lcls = Lcls * \\\n",
    "            tf.cast(positive_classification_mask, dtype=tf.float32)\n",
    "        Lreg = Lreg * tf.cast(positive_regression_mask, dtype=tf.float32)\n",
    "\n",
    "        Lcls = tf.reduce_sum(\n",
    "            Lcls, axis=[1, 2]) / num_positive_detections\n",
    "        Lreg = tf.reduce_sum(\n",
    "            Lreg, axis=[1, 2]) / num_positive_detections\n",
    "\n",
    "        Lcls = tf.reduce_mean(Lcls)\n",
    "        Lreg = tf.reduce_mean(Lreg)\n",
    "        return Lreg, Lcls, tf.reduce_mean(num_positive_detections)\n",
    "        \n",
    "def RetinaNet(input_shape=None, n_classes=None, training=False):\n",
    "    H = W = input_shape\n",
    "    num_anchors = get_anchors(input_shape=H).shape[0]\n",
    "    loss_fn = LossV2(batch_size=BATCH_SIZE, n_classes=N_CLASSES)\n",
    "\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        input_shape=[H, W, 3], weights='imagenet', include_top=False)\n",
    "\n",
    "    resnet_block_output_names = [\n",
    "        'activation_21', 'activation_39', 'activation_48']\n",
    "\n",
    "    resnet_block_outputs = {'C{}'.format(idx + 3): base_model.get_layer(\n",
    "        layer).output for idx, layer in enumerate(resnet_block_output_names)}\n",
    "    resnet_block_outputs = {level: conv_block(\n",
    "        tensor, 256, 1, name=level + '_1x1') for level, tensor in resnet_block_outputs.items()}\n",
    "\n",
    "    P5 = resnet_block_outputs['C5']\n",
    "    P6 = conv_block(base_model.get_layer(\n",
    "        'activation_48').output, 256, 3, strides=2, name='P6')\n",
    "    P6_relu = tf.keras.layers.ReLU(name='P6')(P6)\n",
    "    P7 = conv_block(P6_relu, 256, 3, strides=2, name='P7')\n",
    "    M4 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2}, name='P5_UP')(\n",
    "        P5), resnet_block_outputs['C4']], name='P4_merge')\n",
    "    M3 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2}, name='P4_UP')(\n",
    "        M4), resnet_block_outputs['C3']], name='P3_merge')\n",
    "    P4 = conv_block(M4, 256, 3, name='P4')\n",
    "    P3 = conv_block(M3, 256, 3, name='P3')\n",
    "#         pyrammid_features = [P7, P6, P5, P4, P3]\n",
    "    pyrammid_features = [P3, P4, P5, P6, P7]\n",
    "\n",
    "\n",
    "    classification_subnet = build_classification_subnet(\n",
    "        n_classes=n_classes)\n",
    "    regression_subnet = build_regression_subnet()\n",
    "\n",
    "    classification_outputs = [classification_subnet(\n",
    "        level) for level in pyrammid_features]\n",
    "    regression_outputs = [regression_subnet(\n",
    "        level) for level in pyrammid_features]\n",
    "\n",
    "    classification_head = tf.keras.layers.concatenate(\n",
    "        classification_outputs, axis=1, name='classification_head')\n",
    "    regression_head = tf.keras.layers.concatenate(\n",
    "        regression_outputs, axis=1, name='regression_head')\n",
    "\n",
    "    image_input = base_model.input\n",
    "    classification_targets = tf.keras.layers.Input(shape=[num_anchors])\n",
    "    regression_targets = tf.keras.layers.Input(shape=[num_anchors, 4])\n",
    "    background_mask = tf.keras.layers.Input(shape=[num_anchors])\n",
    "    ignore_mask = tf.keras.layers.Input(shape=[num_anchors])\n",
    "\n",
    "    Lreg, Lcls, _ = tf.keras.layers.Lambda(loss_fn)([classification_targets,\n",
    "                                                     classification_head,\n",
    "                                                     regression_targets,\n",
    "                                                     regression_head,\n",
    "                                                     background_mask,\n",
    "                                                     ignore_mask])\n",
    "\n",
    "    Lreg = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.reshape(x, [-1, 1]), name='box')(Lreg)\n",
    "    Lcls = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.reshape(x, [-1, 1]), name='focal')(Lcls)\n",
    "\n",
    "    if training:\n",
    "        _inputs = [image_input, classification_targets,\n",
    "                   regression_targets, background_mask, ignore_mask]\n",
    "        _outputs = [Lreg, Lcls]\n",
    "    else:\n",
    "        _inputs = [image_input]\n",
    "        _outputs = [classification_head, regression_head]\n",
    "    model =  tf.keras.Model(inputs=_inputs, outputs=_outputs, name='RetinaNet')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = RetinaNet(input_shape=INPUT_SHAPE,\n",
    "                  n_classes=N_CLASSES, training=False)\n",
    "model.load_weights('model_files/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_outputs(image_path):\n",
    "    image = imread(image_path)\n",
    "    image_viz = image.copy()\n",
    "    image = cv2.resize(image, (INPUT_SHAPE, INPUT_SHAPE))\n",
    "    image = image[:, :, ::-1] - np.array([103.939, 116.779, 123.68])\n",
    "    cls_preds, reg_preds = model.predict(image[None, ...])\n",
    "    decoded_boxes, decoded_class_ids, decoded_scores, matched_anchors = \\\n",
    "        decode_targets(cls_preds[0],\n",
    "                       reg_preds[0],\n",
    "                       input_shape=INPUT_SHAPE,\n",
    "                       classification_threshold=0.45,\n",
    "                       nms_threshold=.50)\n",
    "    image_viz = draw_boxes_cv2(image_viz,\n",
    "                               decoded_boxes,\n",
    "                               decoded_class_ids,\n",
    "                               decoded_scores,\n",
    "                               INPUT_SHAPE)\n",
    "    return image_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images\n"
     ]
    }
   ],
   "source": [
    "val_images = glob('../../../../bdd/bdd100k/images/100k/val/*')\n",
    "print('Found {} images'.format(len(val_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes =[\n",
    "            'bus',\n",
    "            'traffic light',\n",
    "            'traffic sign',\n",
    "            'person',\n",
    "            'bike',\n",
    "            'truck',\n",
    "            'motor',\n",
    "            'car',\n",
    "            'train',\n",
    "            'rider'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm test_outputs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ccce71ebda47ab8d86838b22a9de99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-8d87c8e659ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_outputs/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-663c177b27c8>\u001b[0m in \u001b[0;36mvisualize_outputs\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mINPUT_SHAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINPUT_SHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m103.939\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m116.779\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123.68\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcls_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdecoded_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_class_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatched_anchors\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         decode_targets(cls_preds[0],\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3441\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3442\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3443\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3444\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3445\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    560\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 561\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    432\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    433\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 434\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    435\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(10000)):\n",
    "    result = visualize_outputs(val_images[i])\n",
    "    imsave('test_outputs/' + val_images[i].split('/')[-1], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
