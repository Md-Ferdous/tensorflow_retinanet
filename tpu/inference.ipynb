{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srihari/tf2.0/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow 1.14.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.io import imread, imsave\n",
    "from tqdm import tqdm_notebook\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print('Tensorflow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "\n",
    "def compute_anchor_dimensions(ratios=[0.5, 1, 2],\n",
    "                              scales=[1, 1.25, 1.58],\n",
    "                              areas=[32 * 32, 64 * 64, 128 * 128, 256 * 256, 512 * 512]):\n",
    "    anchor_shapes = {'P{}'.format(i): [] for i in range(3, 8)}\n",
    "    for area in areas:\n",
    "        for ratio in ratios:\n",
    "            a_h = np.sqrt(area / ratio)\n",
    "            a_w = area / a_h\n",
    "            for scale in scales:\n",
    "                h = np.int32(scale * a_h)\n",
    "                w = np.int32(scale * a_w)\n",
    "                anchor_shapes['P{}'.format(\n",
    "                    int(np.log2(np.sqrt(area) // 4)))].append([w, h])\n",
    "        anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))] = np.array(\n",
    "            anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))])\n",
    "    return anchor_shapes\n",
    "\n",
    "def get_anchors(input_shape=None, tensor=True):\n",
    "    anchor_dimensions = compute_anchor_dimensions()\n",
    "    anchors = []\n",
    "    for i in range(3, 8):\n",
    "        feature_name = 'P{}'.format(i)\n",
    "        stride = 2**i\n",
    "        feature_size = (input_shape) // stride\n",
    "\n",
    "        dims = anchor_dimensions[feature_name]\n",
    "        dims = dims[None, None, ...]\n",
    "        dims = np.tile(dims, reps=[feature_size, feature_size, 1, 1])\n",
    "\n",
    "        rx = (np.arange(feature_size) + 0.5) * (stride)\n",
    "        ry = (np.arange(feature_size) + 0.5) * (stride)\n",
    "        sx, sy = np.meshgrid(rx, ry)\n",
    "        cxy = np.stack([sx, sy], axis=-1)\n",
    "        cxy = cxy[:, :, None, :]\n",
    "        cxy = np.tile(cxy, reps=[1, 1, 9, 1])\n",
    "        anchors.append(np.reshape(\n",
    "            np.concatenate([cxy, dims], axis=-1), [-1, 4]))\n",
    "    anchors = np.concatenate(anchors, axis=0)\n",
    "    if tensor:\n",
    "        anchors = tf.constant(anchors, dtype=tf.float32)\n",
    "    return anchors\n",
    "\n",
    "def change_box_format(boxes, return_format='xywh'):\n",
    "    boxes = tf.cast(boxes, dtype=tf.float32)\n",
    "    if return_format == 'xywh':\n",
    "\n",
    "        return tf.stack([(boxes[..., 2] + boxes[..., 0]) / 2.0,\n",
    "                         (boxes[..., 3] + boxes[..., 1]) / 2.0,\n",
    "                         boxes[..., 2] - boxes[..., 0],\n",
    "                         boxes[..., 3] - boxes[..., 1]], axis=-1)\n",
    "    elif return_format == 'x1y1x2y2':\n",
    "\n",
    "        return tf.stack([boxes[..., 0] - boxes[..., 2] / 2.0,\n",
    "                         boxes[..., 1] - boxes[..., 3] / 2.0,\n",
    "                         boxes[..., 0] + boxes[..., 2] / 2.0,\n",
    "                         boxes[..., 1] + boxes[..., 3] / 2.0], axis=-1)\n",
    "    return 'You should not be here'\n",
    "\n",
    "def draw_bboxes(image, bbox_list):\n",
    "    image = image / 255.\n",
    "    h, w = image.shape.as_list()[:2]\n",
    "    bboxes = tf.cast(tf.stack([\n",
    "        bbox_list[:, 1] / h, bbox_list[:, 0] /\n",
    "        w, bbox_list[:, 3] / h, bbox_list[:, 2] / w\n",
    "    ], axis=-1), dtype=tf.float32)\n",
    "\n",
    "    colors = tf.random.uniform(maxval=1, shape=[bbox_list.shape[0], 3])\n",
    "    return tf.image.convert_image_dtype(tf.image.draw_bounding_boxes(image[None, ...],\n",
    "                                                                     bboxes[None, ...],\n",
    "                                                                     colors)[0, ...], dtype=tf.uint8)\n",
    "\n",
    "def draw_boxes_cv2(image, bbox_list, class_ids, scores, model_input_shape, classes):\n",
    "    img = np.uint8(image).copy()\n",
    "    bbox_list = np.array(bbox_list, dtype=np.int32)\n",
    "    h, w = img.shape[:2]\n",
    "    h_scale, w_scale = h / model_input_shape, w / model_input_shape\n",
    "    bbox_list = np.int32(bbox_list * np.array([w_scale, h_scale] * 2))\n",
    "    for box, cls_, score in zip(bbox_list, class_ids, scores):\n",
    "        text = classes[cls_] + '' + str(np.round(score, 2))\n",
    "        text_orig = (box[0]+2, box[1]+12)\n",
    "        text_bg_xy1 = (box[0], box[1])\n",
    "        text_bg_xy2 = (box[0]+60, box[1]+18)\n",
    "        img = cv2.rectangle(img, text_bg_xy1,\n",
    "                            text_bg_xy2, [255, 252, 193], -1)\n",
    "        img = cv2.putText(img, text, text_orig, cv2.FONT_HERSHEY_COMPLEX_SMALL, .6, [0, 0, 0], 2, lineType=cv2.LINE_AA)\n",
    "        img = cv2.putText(img, text, text_orig, cv2.FONT_HERSHEY_COMPLEX_SMALL, .6, [255, 255, 255], 1, lineType=cv2.LINE_AA)\n",
    "        img = cv2.rectangle(img, (box[0], box[1]),\n",
    "                            (box[2], box[3]), [30, 15, 200], 1)\n",
    "    return img\n",
    "\n",
    "def decode_targets(classification_outputs,\n",
    "                   regression_outputs,\n",
    "                   input_shape=512,\n",
    "                   classification_threshold=0.05,\n",
    "                   nms_threshold=0.5):\n",
    "    scale_factors = tf.constant([10.0, 10.0, 5.0, 5.0])\n",
    "    anchors = get_anchors(input_shape=input_shape, tensor=True)\n",
    "\n",
    "    class_ids = tf.argmax(classification_outputs, axis=-1)\n",
    "\n",
    "    confidence_scores = tf.reduce_max(\n",
    "        tf.nn.sigmoid(classification_outputs), axis=-1)\n",
    "    regression_outputs = regression_outputs / scale_factors\n",
    "    boxes = tf.concat([(regression_outputs[:, :2] * anchors[:, 2:] + anchors[:, :2]),\n",
    "                       tf.math.exp(\n",
    "                           regression_outputs[:, 2:]) * anchors[:, 2:]\n",
    "                       ], axis=-1)\n",
    "    boxes = change_box_format(boxes, return_format='x1y1x2y2')\n",
    "\n",
    "    nms_indices = tf.image.non_max_suppression(boxes,\n",
    "                                               confidence_scores,\n",
    "                                               score_threshold=classification_threshold,\n",
    "                                               iou_threshold=nms_threshold,\n",
    "                                               max_output_size=100)\n",
    "    final_class_ids = tf.gather(class_ids, nms_indices)\n",
    "    final_scores = tf.gather(confidence_scores, nms_indices)\n",
    "    final_boxes = tf.cast(tf.gather(boxes, nms_indices), dtype=tf.int32)\n",
    "\n",
    "    matched_anchors = tf.gather(anchors, tf.where(\n",
    "        confidence_scores > classification_threshold)[:, 0])\n",
    "    matched_anchors = tf.cast(change_box_format(matched_anchors, return_format='x1y1x2y2'),\n",
    "                              dtype=tf.int32)\n",
    "    return final_boxes, final_class_ids, final_scores, matched_anchors\n",
    "\n",
    "def conv_block(x,\n",
    "               n_filters,\n",
    "               size,\n",
    "               strides=1,\n",
    "               kernel_init='he_normal',\n",
    "               bias_init='zeros',\n",
    "               bn_activated=False, name=''):\n",
    "    x = tf.keras.layers.Conv2D(filters=n_filters,\n",
    "                               kernel_size=size,\n",
    "                               padding='same',\n",
    "                               strides=strides,\n",
    "                               kernel_initializer=kernel_init,\n",
    "                               bias_initializer=bias_init,\n",
    "                               name='conv_' + name if name else None)(x)\n",
    "    if bn_activated:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def Upsampling(tensor, scale=2):\n",
    "    dims = tensor.shape.as_list()[1:-1]\n",
    "    return tf.image.resize_bilinear(tensor, size=[dims[0] * scale, dims[1] * scale], align_corners=True)\n",
    "\n",
    "def build_classification_subnet(n_classes=None, n_anchors=9, p=0.01):\n",
    "    input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
    "    x = input_layer\n",
    "    for i in range(4):\n",
    "        x = conv_block(\n",
    "            x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    bias_init = -np.log((1 - p) / p)\n",
    "    output_layer = tf.keras.layers.Conv2D(filters=n_classes * n_anchors,\n",
    "                                          kernel_size=3,\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "                                              0.0, 0.01),\n",
    "                                          bias_initializer=tf.keras.initializers.Constant(\n",
    "                                              value=bias_init),\n",
    "                                          activation=None)(x)\n",
    "    output_layer = tf.keras.layers.Reshape(\n",
    "        target_shape=[-1, n_classes])(output_layer)\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='classification_subnet')\n",
    "\n",
    "def build_regression_subnet(n_anchors=9):\n",
    "    input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
    "    x = input_layer\n",
    "    for i in range(4):\n",
    "        x = conv_block(\n",
    "            x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    output_layer = tf.keras.layers.Conv2D(filters=4 * n_anchors,\n",
    "                                          kernel_size=3,\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "                                              0.0, 0.01),\n",
    "                                          bias_initializer=tf.keras.initializers.zeros(),\n",
    "                                          activation=None)(x)\n",
    "    output_layer = tf.keras.layers.Reshape(\n",
    "        target_shape=[-1, 4])(output_layer)\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='regression_subnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {value: idx for idx, value in enumerate(['bus',\n",
    "                                                     'traffic light',\n",
    "                                                     'traffic sign',\n",
    "                                                     'person',\n",
    "                                                     'bike',\n",
    "                                                     'truck',\n",
    "                                                     'motor',\n",
    "                                                     'car',\n",
    "                                                     'train',\n",
    "                                                     'rider'])}\n",
    "\n",
    "INPUT_SHAPE = 640\n",
    "BATCH_SIZE = 1\n",
    "N_CLASSES = len(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0906 23:21:39.564548 4505347520 saver.py:795] Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.name-based lookups Saver performs are error-prone.\n",
      "W0906 23:21:39.575070 4505347520 deprecation.py:323] From /Users/srihari/tf2.0/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "class LossV2():\n",
    "    def __init__(self, n_classes=None):\n",
    "        self.num_classes = n_classes\n",
    "        self.smooth_l1 = tf.compat.v2.losses.Huber(delta=0.11, reduction='none')\n",
    "\n",
    "    def focal_loss(self, y_true, y_pred, alpha=0.25, gamma=2):\n",
    "        y_true = tf.one_hot(\n",
    "            tf.cast(y_true, dtype=tf.int32), depth=self.num_classes + 1)\n",
    "        y_true = y_true[:, :, 1:]\n",
    "        y_pred_ = tf.sigmoid(y_pred)\n",
    "\n",
    "        at = alpha * y_true + (1 - y_true) * (1 - alpha)\n",
    "        pt = y_true * y_pred_ + (1 - y_true) * (1 - y_pred_)\n",
    "        f_loss = at * tf.pow(1 - pt, gamma) * tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "\n",
    "        return f_loss\n",
    "\n",
    "    def smooth_l1_(self, y_true, y_pred, sigma=3.0):\n",
    "        y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
    "        sigma = tf.cast(sigma, dtype=y_pred.dtype)\n",
    "        x = y_true - y_pred\n",
    "        abs_x = tf.abs(x)\n",
    "        sigma_squared = tf.square(sigma)\n",
    "        quadratic = 0.5 * tf.square(sigma * x)\n",
    "        linear = abs_x - (0.5 / sigma_squared)\n",
    "        smooth_l1_loss = tf.where(\n",
    "            tf.less_equal(abs_x, 1. / sigma_squared), quadratic, linear)\n",
    "        return smooth_l1_loss\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        classification_targets = tensor[0]\n",
    "        classification_predictions = tensor[1]\n",
    "        regression_targets = tensor[2]\n",
    "        regression_predictions = tensor[3]\n",
    "        background_mask = tensor[4]\n",
    "        ignore_mask = tensor[5]\n",
    "\n",
    "        background_mask = tf.cast(\n",
    "            background_mask, dtype=tf.bool, name='bg_cast')\n",
    "        ignore_mask = tf.cast(ignore_mask, dtype=tf.bool, name='ig_cast')\n",
    "\n",
    "        num_positive_detections = tf.maximum(tf.reduce_sum(\n",
    "            tf.cast(background_mask, dtype=tf.float32), axis=-1), 1.0)\n",
    "\n",
    "        positive_classification_mask = tf.expand_dims(\n",
    "            tf.logical_not(ignore_mask), axis=-1)\n",
    "        positive_classification_mask = tf.tile(\n",
    "            positive_classification_mask, multiples=[1, 1, self.num_classes])\n",
    "\n",
    "        positive_regression_mask = tf.expand_dims(background_mask, axis=-1)\n",
    "        positive_regression_mask = tf.tile(\n",
    "            positive_regression_mask, multiples=[1, 1, 4])\n",
    "\n",
    "        Lcls = self.focal_loss(classification_targets,\n",
    "                               classification_predictions)\n",
    "        Lreg = self.smooth_l1(regression_targets, regression_predictions)\n",
    "        Lcls = Lcls * \\\n",
    "            tf.cast(positive_classification_mask, dtype=tf.float32)\n",
    "        Lreg = Lreg * tf.cast(positive_regression_mask, dtype=tf.float32)\n",
    "\n",
    "        Lcls = tf.reduce_sum(\n",
    "            Lcls, axis=[1, 2]) / num_positive_detections\n",
    "        Lreg = tf.reduce_sum(\n",
    "            Lreg, axis=[1, 2]) / num_positive_detections\n",
    "\n",
    "        Lcls = tf.reduce_mean(Lcls)\n",
    "        Lreg = tf.reduce_mean(Lreg)\n",
    "        return Lreg, Lcls, tf.reduce_mean(num_positive_detections)\n",
    "        \n",
    "def RetinaNet(input_shape=None, n_classes=None, training=False):\n",
    "    H = W = input_shape\n",
    "    num_anchors = get_anchors(input_shape=H).shape[0]\n",
    "    loss_fn = LossV2(n_classes=n_classes)\n",
    "\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        input_shape=[H, W, 3], weights='imagenet', include_top=False)\n",
    "\n",
    "    resnet_block_output_names = [\n",
    "        'activation_21', 'activation_39', 'activation_48']\n",
    "\n",
    "    resnet_block_outputs = {'C{}'.format(idx + 3): base_model.get_layer(\n",
    "        layer).output for idx, layer in enumerate(resnet_block_output_names)}\n",
    "    resnet_block_outputs = {level: conv_block(\n",
    "        tensor, 256, 1, name=level + '_1x1') for level, tensor in resnet_block_outputs.items()}\n",
    "\n",
    "    P5 = resnet_block_outputs['C5']\n",
    "    P6 = conv_block(base_model.get_layer(\n",
    "        'activation_48').output, 256, 3, strides=2, name='P6')\n",
    "    P6_relu = tf.keras.layers.ReLU(name='P6')(P6)\n",
    "    P7 = conv_block(P6_relu, 256, 3, strides=2, name='P7')\n",
    "    M4 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2}, name='P5_UP')(\n",
    "        P5), resnet_block_outputs['C4']], name='P4_merge')\n",
    "    M3 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2}, name='P4_UP')(\n",
    "        M4), resnet_block_outputs['C3']], name='P3_merge')\n",
    "    P4 = conv_block(M4, 256, 3, name='P4')\n",
    "    P3 = conv_block(M3, 256, 3, name='P3')\n",
    "#         pyrammid_features = [P7, P6, P5, P4, P3]\n",
    "    pyrammid_features = [P3, P4, P5, P6, P7]\n",
    "\n",
    "\n",
    "    classification_subnet = build_classification_subnet(\n",
    "        n_classes=n_classes)\n",
    "    regression_subnet = build_regression_subnet()\n",
    "\n",
    "    classification_outputs = [classification_subnet(\n",
    "        level) for level in pyrammid_features]\n",
    "    regression_outputs = [regression_subnet(\n",
    "        level) for level in pyrammid_features]\n",
    "\n",
    "    classification_head = tf.keras.layers.concatenate(\n",
    "        classification_outputs, axis=1, name='classification_head')\n",
    "    regression_head = tf.keras.layers.concatenate(\n",
    "        regression_outputs, axis=1, name='regression_head')\n",
    "\n",
    "    image_input = base_model.input\n",
    "    classification_targets = tf.keras.layers.Input(shape=[num_anchors])\n",
    "    regression_targets = tf.keras.layers.Input(shape=[num_anchors, 4])\n",
    "    background_mask = tf.keras.layers.Input(shape=[num_anchors])\n",
    "    ignore_mask = tf.keras.layers.Input(shape=[num_anchors])\n",
    "\n",
    "    Lreg, Lcls, _ = tf.keras.layers.Lambda(loss_fn)([classification_targets,\n",
    "                                                     classification_head,\n",
    "                                                     regression_targets,\n",
    "                                                     regression_head,\n",
    "                                                     background_mask,\n",
    "                                                     ignore_mask])\n",
    "\n",
    "    Lreg = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.reshape(x, [-1, 1]), name='box')(Lreg)\n",
    "    Lcls = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.reshape(x, [-1, 1]), name='focal')(Lcls)\n",
    "\n",
    "    if training:\n",
    "        _inputs = [image_input, classification_targets,\n",
    "                   regression_targets, background_mask, ignore_mask]\n",
    "        _outputs = [Lreg, Lcls]\n",
    "    else:\n",
    "        _inputs = [image_input]\n",
    "        _outputs = [classification_head, regression_head]\n",
    "    model =  tf.keras.Model(inputs=_inputs, outputs=_outputs, name='RetinaNet')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = RetinaNet(input_shape=INPUT_SHAPE,\n",
    "                  n_classes=N_CLASSES, training=False)\n",
    "saver = tf.train.Saver(model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_outputs(image_path):\n",
    "    classes =[\n",
    "            'Bus',\n",
    "            'TLight',\n",
    "            'Tsign',\n",
    "            'Person',\n",
    "            'Bike',\n",
    "            'Truck',\n",
    "            'Motor',\n",
    "            'Car',\n",
    "            'Train',\n",
    "            'Rider'\n",
    "    ]\n",
    "    image = imread(image_path)\n",
    "    image_viz = image.copy()\n",
    "    image = cv2.resize(image, (INPUT_SHAPE, INPUT_SHAPE))\n",
    "    image = image[:, :, ::-1] - np.array([103.939, 116.779, 123.68])\n",
    "    cls_preds, reg_preds = model.predict(image[None, ...])\n",
    "    decoded_boxes, decoded_class_ids, decoded_scores, matched_anchors = \\\n",
    "        decode_targets(cls_preds[0],\n",
    "                       reg_preds[0],\n",
    "                       input_shape=INPUT_SHAPE,\n",
    "                       classification_threshold=0.35,\n",
    "                       nms_threshold=.50)\n",
    "    image_viz = draw_boxes_cv2(image_viz,\n",
    "                               decoded_boxes,\n",
    "                               decoded_class_ids,\n",
    "                               decoded_scores,\n",
    "                               INPUT_SHAPE, \n",
    "                               classes)\n",
    "    return image_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(K.get_session(), tf.train.latest_checkpoint('model_files_v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images\n"
     ]
    }
   ],
   "source": [
    "val_images = sorted(glob('../../../../bdd/bdd100k/images/100k/val/*'))\n",
    "print('Found {} images'.format(len(val_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: test_outputs/*: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm test_outputs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b5634a7e2c4fde9095f94907499868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(6000, 6500)):\n",
    "    result = visualize_outputs(val_images[i])\n",
    "    imsave('test_outputs/' + val_images[i].split('/')[-1], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
