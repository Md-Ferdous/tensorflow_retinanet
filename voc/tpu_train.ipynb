{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "tpu_train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahvQZWQSfoEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a9e70cd3-ee1b-4562-85bf-764706ef576b"
      },
      "source": [
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('Tensorflow', tf.__version__)\n",
        "\n",
        "\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.config.experimental_connect_to_host(cluster_resolver.get_master())\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0901 16:20:52.736341 139673780430720 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensorflow 1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpWHjvU-foEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  def imshow(image):\n",
        "      plt.figure(figsize=(12, 12))\n",
        "      plt.axis('off')\n",
        "      plt.imshow(image)\n",
        "\n",
        "\n",
        "  def compute_anchor_dimensions(ratios=[0.5, 1, 2],\n",
        "                                scales=[1, 1.25, 1.58],\n",
        "                                areas=[32 * 32, 64 * 64, 128 * 128, 256 * 256, 512 * 512]):\n",
        "      anchor_shapes = {'P{}'.format(i): [] for i in range(3, 8)}\n",
        "      for area in areas:\n",
        "          for ratio in ratios:\n",
        "              a_h = np.sqrt(area / ratio)\n",
        "              a_w = area / a_h\n",
        "              for scale in scales:\n",
        "                  h = np.int32(scale * a_h)\n",
        "                  w = np.int32(scale * a_w)\n",
        "                  anchor_shapes['P{}'.format(\n",
        "                      int(np.log2(np.sqrt(area) // 4)))].append([w, h])\n",
        "          anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))] = np.array(\n",
        "              anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))])\n",
        "      return anchor_shapes\n",
        "\n",
        "\n",
        "  def get_anchors(input_shape=512, tensor=True):\n",
        "      anchor_dimensions = compute_anchor_dimensions()\n",
        "      anchors = []\n",
        "      for i in range(3, 8):\n",
        "          feature_name = 'P{}'.format(i)\n",
        "          stride = 2**i\n",
        "          feature_size = (input_shape) // stride\n",
        "\n",
        "          dims = anchor_dimensions[feature_name]\n",
        "          dims = dims[None, None, ...]\n",
        "          dims = np.tile(dims, reps=[feature_size, feature_size, 1, 1])\n",
        "\n",
        "          rx = (np.arange(feature_size) + 0.5) * (stride)\n",
        "          ry = (np.arange(feature_size) + 0.5) * (stride)\n",
        "          sx, sy = np.meshgrid(rx, ry)\n",
        "          cxy = np.stack([sx, sy], axis=-1)\n",
        "          cxy = cxy[:, :, None, :]\n",
        "          cxy = np.tile(cxy, reps=[1, 1, 9, 1])\n",
        "          anchors.append(np.reshape(\n",
        "              np.concatenate([cxy, dims], axis=-1), [-1, 4]))\n",
        "      anchors = np.concatenate(anchors, axis=0)\n",
        "      if tensor:\n",
        "          anchors = tf.constant(anchors, dtype=tf.float32)\n",
        "      return anchors\n",
        "\n",
        "\n",
        "  @tf.function()\n",
        "  def compute_iou(boxes1, boxes2):\n",
        "      boxes1 = tf.cast(boxes1, dtype=tf.float32)\n",
        "      boxes2 = tf.cast(boxes2, dtype=tf.float32)\n",
        "\n",
        "      boxes1_t = change_box_format(boxes1, return_format='x1y1x2y2')\n",
        "      boxes2_t = change_box_format(boxes2, return_format='x1y1x2y2')\n",
        "\n",
        "      lu = tf.maximum(boxes1_t[:, None, :2], boxes2_t[:, :2])\n",
        "      rd = tf.minimum(boxes1_t[:, None, 2:], boxes2_t[:, 2:])\n",
        "\n",
        "      intersection = tf.maximum(0.0, rd - lu)\n",
        "      inter_square = intersection[:, :, 0] * intersection[:, :, 1]\n",
        "\n",
        "      square1 = boxes1[:, 2] * boxes1[:, 3]\n",
        "      square2 = boxes2[:, 2] * boxes2[:, 3]\n",
        "\n",
        "      union_square = tf.maximum(square1[:, None] + square2 - inter_square, 1e-10)\n",
        "      return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)\n",
        "\n",
        "\n",
        "  def change_box_format(boxes, return_format='xywh'):\n",
        "      boxes = tf.cast(boxes, dtype=tf.float32)\n",
        "      if return_format == 'xywh':\n",
        "\n",
        "          return tf.stack([(boxes[..., 2] + boxes[..., 0]) / 2.0,\n",
        "                           (boxes[..., 3] + boxes[..., 1]) / 2.0,\n",
        "                           boxes[..., 2] - boxes[..., 0],\n",
        "                           boxes[..., 3] - boxes[..., 1]], axis=-1)\n",
        "      elif return_format == 'x1y1x2y2':\n",
        "\n",
        "          return tf.stack([boxes[..., 0] - boxes[..., 2] / 2.0,\n",
        "                           boxes[..., 1] - boxes[..., 3] / 2.0,\n",
        "                           boxes[..., 0] + boxes[..., 2] / 2.0,\n",
        "                           boxes[..., 1] + boxes[..., 3] / 2.0], axis=-1)\n",
        "      return 'You should not be here'\n",
        "\n",
        "\n",
        "  def draw_bboxes(image, bbox_list):\n",
        "      image = image / 255.\n",
        "      h, w = image.shape.as_list()[:2]\n",
        "      bboxes = tf.cast(tf.stack([\n",
        "          bbox_list[:, 1] / h, bbox_list[:, 0] /\n",
        "          w, bbox_list[:, 3] / h, bbox_list[:, 2] / w\n",
        "      ], axis=-1), dtype=tf.float32)\n",
        "\n",
        "      colors = tf.random.uniform(maxval=1, shape=[bbox_list.shape[0], 3])\n",
        "      return tf.image.convert_image_dtype(tf.image.draw_bounding_boxes(image[None, ...],\n",
        "                                                                       bboxes[None, ...],\n",
        "                                                                       colors)[0, ...], dtype=tf.uint8)\n",
        "\n",
        "\n",
        "  def draw_boxes_cv2(image, bbox_list):\n",
        "      img = np.uint8(image).copy()\n",
        "      bbox_list = np.array(bbox_list, dtype=np.int32)\n",
        "      for box in bbox_list:\n",
        "          img = cv2.rectangle(img, (box[0], box[1]),\n",
        "                              (box[2], box[3]), [0, 0, 200], 3)\n",
        "      return img\n",
        "\n",
        "\n",
        "  def get_label(label_path, class_map, input_shape=512):\n",
        "      with open(label_path, 'r') as f:\n",
        "          temp = json.load(f)\n",
        "      bbox = []\n",
        "      class_ids = []\n",
        "      for obj in temp['frames'][0]['objects']:\n",
        "          if 'box2d' in obj:\n",
        "              x1 = obj['box2d']['x1']\n",
        "              y1 = obj['box2d']['y1']\n",
        "              x2 = obj['box2d']['x2']\n",
        "              y2 = obj['box2d']['y2']\n",
        "              bbox.append(np.array([x1, y1, x2, y2]))\n",
        "              class_ids.append(class_map[obj['category']])\n",
        "      bbox = np.array(bbox, dtype=np.float32)\n",
        "      H, W = 720, 1280.\n",
        "      bbox[:, 0] = bbox[:, 0] / W\n",
        "      bbox[:, 2] = bbox[:, 2] / W\n",
        "      bbox[:, 1] = bbox[:, 1] / H\n",
        "      bbox[:, 3] = bbox[:, 3] / H\n",
        "      bbox = np.int32(bbox * input_shape)\n",
        "      class_ids = np.array(class_ids, dtype=np.float32)[..., None]\n",
        "      return np.concatenate([bbox, class_ids], axis=-1)\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def get_image(image_path, input_shape=None):\n",
        "      H = W = input_shape\n",
        "      img = tf.io.read_file(image_path)\n",
        "      img = tf.image.decode_jpeg(img)\n",
        "      img = tf.image.resize(img, size=[H, W])\n",
        "      img = img[:, :, ::-1] - tf.constant([103.939, 116.779, 123.68])\n",
        "      return img\n",
        "\n",
        "\n",
        "  def load_data(input_shape=None):\n",
        "      def load_data(image_path, label):\n",
        "          images = get_image(image_path, input_shape=input_shape)\n",
        "          targets = encode_targets(label, input_shape=input_shape)\n",
        "\n",
        "          return images, targets\n",
        "      return load_data\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def encode_targets(label, input_shape=None):\n",
        "      \"\"\"We use the assignment rule from RPN.\n",
        "          Faster RCNN box coder follows the coding schema described below:\n",
        "              ty = (y - ya) / ha\n",
        "              tx = (x - xa) / wa\n",
        "              th = log(h / ha)\n",
        "              tw = log(w / wa)\n",
        "          where x, y, w, h denote the box's center coordinates, width and height\n",
        "          respectively. Similarly, xa, ya, wa, ha denote the anchor's center\n",
        "          coordinates, width and height. tx, ty, tw and th denote the\n",
        "          anchor-encoded center, width and height respectively.\n",
        "          The open-source implementation recommends using [10.0, 10.0, 5.0, 5.0] as\n",
        "          scale factors.\n",
        "          See http://arxiv.org/abs/1506.01497 for details. \n",
        "          Set achors with iou < 0.5 to 0 and\n",
        "          set achors with iou iou > 0.4 && < 0.5 to -1. Convert\n",
        "          regression targets into one-hot encoding (N, \n",
        "          in loss_fn and exclude background class in loss calculation.\n",
        "          Use [0, 0, 0, ... 0, n_classes] (all units set to zeros) to represent\n",
        "          background class.\n",
        "      \"\"\"\n",
        "      scale_factors = tf.constant([5.0, 5.0, 5.0, 5.0])\n",
        "      anchors = get_anchors(input_shape=input_shape, tensor=True)\n",
        "      gt_boxes = label[:, :4]\n",
        "      gt_boxes = change_box_format(gt_boxes, return_format='xywh')\n",
        "      gt_class_ids = label[:, 4]\n",
        "      ious = compute_iou(anchors, gt_boxes)\n",
        "\n",
        "      max_ious = tf.reduce_max(ious, axis=1)\n",
        "      max_ids = tf.argmax(ious, axis=1, output_type=tf.int32)\n",
        "\n",
        "      background_mask = max_ious > 0.5\n",
        "      ignore_mask = tf.logical_and(max_ious > 0.4, max_ious < 0.5)\n",
        "\n",
        "      selected_gt_boxes = tf.gather(gt_boxes, max_ids)\n",
        "      selected_gt_class_ids = 1. + tf.gather(gt_class_ids, max_ids)\n",
        "\n",
        "      selected_gt_class_ids = selected_gt_class_ids * \\\n",
        "          tf.cast(background_mask, dtype=tf.float32)\n",
        "      classification_targets = selected_gt_class_ids - tf.cast(\n",
        "          ignore_mask, dtype=tf.float32)\n",
        "      regression_targets = tf.stack([\n",
        "          (selected_gt_boxes[:, 0] - anchors[:, 0]) / anchors[:, 2],\n",
        "          (selected_gt_boxes[:, 1] - anchors[:, 1]) / anchors[:, 3],\n",
        "          tf.math.log(selected_gt_boxes[:, 2] / anchors[:, 2]),\n",
        "          tf.math.log(selected_gt_boxes[:, 3] / anchors[:, 3])\n",
        "      ], axis=-1)\n",
        "      regression_targets = regression_targets * scale_factors\n",
        "      return (tf.cast(classification_targets, dtype=tf.int32),\n",
        "              regression_targets,\n",
        "              background_mask,\n",
        "              ignore_mask)\n",
        "\n",
        "\n",
        "  def decode_targets(classification_outputs,\n",
        "                     regression_outputs,\n",
        "                     input_shape=512,\n",
        "                     classification_threshold=0.05,\n",
        "                     nms_threshold=0.5):\n",
        "      scale_factors = tf.constant([5.0, 5.0, 5.0, 5.0])\n",
        "      anchors = get_anchors(input_shape=input_shape, tensor=True)\n",
        "\n",
        "      '''gt targets are in one hot form, no need to apply  sigmoid to check correctness, use sigmoid during actual inference'''\n",
        "      class_ids = tf.argmax(classification_outputs, axis=-1)\n",
        "\n",
        "      confidence_scores = tf.reduce_max(\n",
        "          tf.nn.sigmoid(classification_outputs), axis=-1)\n",
        "      regression_outputs = regression_outputs / scale_factors\n",
        "      boxes = tf.concat([(regression_outputs[:, :2] * anchors[:, 2:] + anchors[:, :2]),\n",
        "                         tf.math.exp(regression_outputs[:, 2:]) * anchors[:, 2:]\n",
        "                         ], axis=-1)\n",
        "      boxes = change_box_format(boxes, return_format='x1y1x2y2')\n",
        "\n",
        "      nms_indices = tf.image.non_max_suppression(boxes,\n",
        "                                                 confidence_scores,\n",
        "                                                 score_threshold=classification_threshold,\n",
        "                                                 iou_threshold=nms_threshold,\n",
        "                                                 max_output_size=200)\n",
        "      final_class_ids = tf.gather(class_ids, nms_indices)\n",
        "      final_scores = tf.gather(confidence_scores, nms_indices)\n",
        "      final_boxes = tf.cast(tf.gather(boxes, nms_indices), dtype=tf.int32)\n",
        "\n",
        "      matched_anchors = tf.gather(anchors, tf.where(\n",
        "          confidence_scores > classification_threshold)[:, 0])\n",
        "      matched_anchors = tf.cast(change_box_format(matched_anchors, return_format='x1y1x2y2'),\n",
        "                                dtype=tf.int32)\n",
        "      return final_boxes, final_class_ids, final_scores, matched_anchors\n",
        "\n",
        "\n",
        "  def conv_block(x,\n",
        "                 n_filters,\n",
        "                 size,\n",
        "                 strides=1,\n",
        "                 kernel_init='he_normal',\n",
        "                 bias_init='zeros',\n",
        "                 bn_activated=False, name=''):\n",
        "      x = tf.keras.layers.Conv2D(filters=n_filters,\n",
        "                                 kernel_size=size,\n",
        "                                 padding='same',\n",
        "                                 strides=strides,\n",
        "                                 kernel_initializer=kernel_init,\n",
        "                                 bias_initializer=bias_init,\n",
        "                                 name='conv_' + name if name else None)(x)\n",
        "      if bn_activated:\n",
        "          x = tf.keras.layers.BatchNormalization()(x)\n",
        "          x = tf.keras.layers.ReLU()(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "  def Upsampling(tensor, scale=2):\n",
        "      dims = tensor.shape.as_list()[1:-1]\n",
        "      return tf.image.resize_bilinear(tensor, size=[dims[0] * scale, dims[1] * scale], align_corners=True)\n",
        "\n",
        "\n",
        "  def build_classification_subnet(n_classes=None, n_anchors=9, p=0.01):\n",
        "      input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
        "      x = input_layer\n",
        "      for i in range(4):\n",
        "          x = conv_block(\n",
        "              x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
        "          x = tf.keras.layers.ReLU()(x)\n",
        "      bias_init = -np.log((1 - p) / p)\n",
        "      output_layer = tf.keras.layers.Conv2D(filters=n_classes * n_anchors,\n",
        "                                            kernel_size=3,\n",
        "                                            padding='same',\n",
        "                                            kernel_initializer=tf.keras.initializers.RandomNormal(\n",
        "                                                0.0, 0.01),\n",
        "                                            bias_initializer=tf.keras.initializers.Constant(\n",
        "                                                value=bias_init),\n",
        "                                            activation=None)(x)\n",
        "      output_layer = tf.keras.layers.Reshape(\n",
        "          target_shape=[-1, n_classes])(output_layer)\n",
        "      return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='classification_subnet')\n",
        "\n",
        "\n",
        "  def build_regression_subnet(n_anchors=9):\n",
        "      input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
        "      x = input_layer\n",
        "      for i in range(4):\n",
        "          x = conv_block(\n",
        "              x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
        "          x = tf.keras.layers.ReLU()(x)\n",
        "      output_layer = tf.keras.layers.Conv2D(filters=4 * n_anchors,\n",
        "                                            kernel_size=3,\n",
        "                                            padding='same',\n",
        "                                            kernel_initializer=tf.keras.initializers.RandomNormal(\n",
        "                                                0.0, 0.01),\n",
        "                                            bias_initializer=tf.keras.initializers.zeros(),\n",
        "                                            activation=None)(x)\n",
        "      output_layer = tf.keras.layers.Reshape(target_shape=[-1, 4])(output_layer)\n",
        "      return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='regression_subnet')\n",
        "\n",
        "\n",
        "  class LossV2():\n",
        "      def __init__(self, batch_size=None, n_classes=None):\n",
        "          self.num_classes = n_classes\n",
        "          self.global_batch_size = batch_size\n",
        "\n",
        "      def focal_loss(self, y_true, y_pred, alpha=0.25, gamma=2):\n",
        "          y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.num_classes + 1)\n",
        "          y_true = y_true[:, :, 1:]\n",
        "          y_pred = tf.sigmoid(y_pred)\n",
        "\n",
        "          at = alpha * y_true + (1 - y_true) * (1 - alpha)\n",
        "          pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "          f_loss = -at * tf.pow(1 - pt, gamma) * tf.math.log(pt)\n",
        "          return f_loss\n",
        "\n",
        "      def smooth_l1(self, y_true, y_pred, sigma=3.0):\n",
        "          y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
        "          sigma = tf.cast(sigma, dtype=y_pred.dtype)\n",
        "          x = y_true - y_pred\n",
        "          abs_x = tf.abs(x)\n",
        "          sigma_squared = tf.square(sigma)\n",
        "          quadratic = 0.5 * tf.square(sigma * x)\n",
        "          linear = abs_x - (0.5 / sigma_squared)\n",
        "          smooth_l1_loss = tf.where(tf.less(abs_x, 1./sigma_squared), quadratic, linear)\n",
        "          return smooth_l1_loss\n",
        "\n",
        "      def __call__(self, tensor):\n",
        "          classification_targets = tensor[0]\n",
        "          classification_predictions = tensor[1]\n",
        "          regression_targets = tensor[2]\n",
        "          regression_predictions = tensor[3]\n",
        "          background_mask = tensor[4]\n",
        "          ignore_mask = tensor[5]\n",
        "          \n",
        "          background_mask = tf.cast(background_mask, dtype=tf.bool, name='bg_cast')\n",
        "          ignore_mask = tf.cast(ignore_mask, dtype=tf.bool, name='ig_cast')\n",
        "\n",
        "          num_positive_detections = tf.maximum(tf.reduce_sum(\n",
        "              tf.cast(background_mask, dtype=tf.float32), axis=-1), 1.0)\n",
        "#           num_positive_detections = tf.maximum(tf.reduce_sum(\n",
        "#               background_mask, axis=-1), 1.0)\n",
        "              \n",
        "          positive_classification_mask = tf.expand_dims(\n",
        "              tf.logical_not(ignore_mask), axis=-1)\n",
        "          positive_classification_mask = tf.tile(\n",
        "              positive_classification_mask, multiples=[1, 1, self.num_classes])\n",
        "\n",
        "          positive_regression_mask = tf.expand_dims(background_mask, axis=-1)\n",
        "          positive_regression_mask = tf.tile(\n",
        "              positive_regression_mask, multiples=[1, 1, 4])\n",
        "\n",
        "          Lcls = self.focal_loss(classification_targets,\n",
        "                                 classification_predictions)\n",
        "          Lreg = self.smooth_l1(regression_targets, regression_predictions)\n",
        "          Lcls = Lcls * tf.cast(positive_classification_mask, dtype=tf.float32)\n",
        "          Lreg = Lreg * tf.cast(positive_regression_mask, dtype=tf.float32)\n",
        "\n",
        "          Lcls = tf.reduce_sum(\n",
        "              Lcls, axis=[1, 2]) / num_positive_detections\n",
        "          Lreg = tf.reduce_sum(\n",
        "              Lreg, axis=[1, 2]) / num_positive_detections\n",
        "\n",
        "          Lcls = tf.reduce_mean(Lcls)\n",
        "          Lreg = tf.reduce_mean(Lreg)\n",
        "          return Lreg, Lcls, tf.reduce_mean(num_positive_detections)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_aGcRv6foEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_SHAPE = 640\n",
        "BATCH_SIZE = 64\n",
        "N_CLASSES = 20\n",
        "EPOCHS = 200\n",
        "training_steps = 2501 // BATCH_SIZE\n",
        "val_steps = 2510 // BATCH_SIZE\n",
        "LR = 1e-5 * 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqxKuvBefoEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  @tf.function\n",
        "  def flip_data(image, boxes, w):\n",
        "      if tf.random.uniform(()) > 0.5:\n",
        "          image = tf.image.flip_left_right(image)\n",
        "          boxes = tf.stack([\n",
        "              w - boxes[:, 2],\n",
        "              boxes[:, 1],\n",
        "              w - boxes[:, 0],\n",
        "              boxes[:, 3]\n",
        "          ], axis=-1)\n",
        "      return image, boxes\n",
        "\n",
        "\n",
        "  def load_data(input_shape):\n",
        "      h, w = input_shape, input_shape\n",
        "\n",
        "      @tf.function\n",
        "      def load_data_(example, input_shape=input_shape):\n",
        "          image = tf.cast(example['image'], dtype=tf.float32)\n",
        "          boxes_ = example['objects']['bbox']\n",
        "          class_ids = tf.expand_dims(\n",
        "              tf.cast(example['objects']['label'], dtype=tf.float32), axis=-1)\n",
        "          image = tf.image.resize(image, size=[h, w])\n",
        "\n",
        "          boxes = tf.stack([\n",
        "              tf.clip_by_value(boxes_[:, 1] * w, 0, w),\n",
        "              tf.clip_by_value(boxes_[:, 0] * h, 0, h),\n",
        "              tf.clip_by_value(boxes_[:, 3] * w, 0, w),\n",
        "              tf.clip_by_value(boxes_[:, 2] * h, 0, h)\n",
        "          ], axis=-1)\n",
        "          image, boxes = flip_data(image, boxes, w)\n",
        "          label = tf.concat([boxes, class_ids], axis=-1)\n",
        "          cls_targets, reg_targets, bg, ig = encode_targets(\n",
        "              label, input_shape=input_shape)\n",
        "          bg = tf.cast(bg, dtype=tf.float32)\n",
        "          ig = tf.cast(ig, dtype=tf.float32)\n",
        "          cls_targets = tf.cast(cls_targets, dtype=tf.float32)\n",
        "          return (image, cls_targets, reg_targets, bg, ig), (tf.ones((1, )), tf.ones((1, )))\n",
        "      return load_data_\n",
        "\n",
        "\n",
        "  train_dataset = tfds.load('voc2007', data_dir='gs://srihari-datasets/', shuffle_files=False, split=['train'])[0]\n",
        "  train_dataset = train_dataset.map(load_data(\n",
        "      input_shape=INPUT_SHAPE), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
        "  train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  val_dataset = tfds.load('voc2007', data_dir='gs://srihari-datasets/', shuffle_files=False,\n",
        "                          split=['validation'])[0]\n",
        "  val_dataset = val_dataset.map(load_data(\n",
        "      input_shape=INPUT_SHAPE), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
        "  val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  train_dataset, val_dataset\n",
        "\n",
        "\n",
        "  # i = 0\n",
        "  # for batch in train_dataset.take(1):\n",
        "  #     break\n",
        "  # image, cls_targets, reg_targets, _, _ = batch[0]\n",
        "  # classification_outputs = tf.one_hot(tf.cast(cls_targets[i], dtype=tf.int32), depth=N_CLASSES + 1)[:, 1:]\n",
        "  # regression_outputs = reg_targets[i]\n",
        "  # image = image[i]\n",
        "  # scale_factors = tf.constant([5.0, 5.0, 5.0, 5.0])\n",
        "  # anchors = get_anchors(input_shape=INPUT_SHAPE, tensor=True)\n",
        "  # class_ids = tf.argmax(classification_outputs, axis=-1)\n",
        "  # confidence_scores = tf.reduce_max(classification_outputs, axis=-1)\n",
        "  # regression_outputs = regression_outputs / scale_factors\n",
        "  # boxes = tf.concat([(regression_outputs[:, :2] * anchors[:, 2:] + anchors[:, :2]),\n",
        "  #                    tf.math.exp(regression_outputs[:, 2:]) * anchors[:, 2:]\n",
        "  #                    ], axis=-1)\n",
        "  # boxes = change_box_format(boxes, return_format='x1y1x2y2')\n",
        "\n",
        "  # nms_indices = tf.image.non_max_suppression(boxes,\n",
        "  #                                            confidence_scores,\n",
        "  #                                            score_threshold=0.05,\n",
        "  #                                            iou_threshold=0.5,\n",
        "  #                                            max_output_size=200)\n",
        "  # final_class_ids = tf.gather(class_ids, nms_indices)\n",
        "  # final_scores = tf.gather(confidence_scores, nms_indices)\n",
        "  # final_boxes = tf.cast(tf.gather(boxes, nms_indices), dtype=tf.int32)\n",
        "\n",
        "  # matched_anchors = tf.gather(anchors, tf.where(confidence_scores > 0.05)[:, 0])\n",
        "  # matched_anchors = tf.cast(change_box_format(matched_anchors, return_format='x1y1x2y2'),\n",
        "  #                           dtype=tf.int32)\n",
        "  # img = draw_boxes_cv2(image, boxes)\n",
        "  # imshow(img)\n",
        "  # print(final_boxes.numpy())\n",
        "  # print(final_class_ids.numpy())\n",
        "  # print(final_scores.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5n59juRfoEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72e0cd17-fca1-4673-a615-baf763e7b22a"
      },
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  def RetinaNet(input_shape=None, n_classes=None, training=False):\n",
        "      H = W = input_shape\n",
        "      num_anchors = get_anchors(input_shape=H).shape[0]\n",
        "      loss_fn = LossV2(batch_size=BATCH_SIZE, n_classes=N_CLASSES)\n",
        "\n",
        "      base_model = tf.keras.applications.ResNet50(\n",
        "          input_shape=[H, W, 3], weights=None, include_top=False)\n",
        "\n",
        "      resnet_block_output_names = ['activation_21', 'activation_39', 'activation_48']\n",
        "\n",
        "      resnet_block_outputs = {'C{}'.format(idx + 3): base_model.get_layer(\n",
        "          layer).output for idx, layer in enumerate(resnet_block_output_names)}\n",
        "      resnet_block_outputs = {level: conv_block(\n",
        "          tensor, 256, 1, name=level + '_1x1') for level, tensor in resnet_block_outputs.items()}\n",
        "\n",
        "      P5 = resnet_block_outputs['C5']\n",
        "      P6 = conv_block(base_model.get_layer(\n",
        "          'activation_48').output, 256, 3, strides=2, name='P6')\n",
        "      P6_relu = tf.keras.layers.ReLU(name='P6')(P6)\n",
        "      P7 = conv_block(P6_relu, 256, 3, strides=2, name='P7')\n",
        "      M4 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2}, name='P5_UP')(\n",
        "          P5), resnet_block_outputs['C4']], name='P4_merge')\n",
        "      M3 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2}, name='P4_UP')(\n",
        "          M4), resnet_block_outputs['C3']], name='P3_merge')\n",
        "      P4 = conv_block(M4, 256, 3, name='P4')\n",
        "      P3 = conv_block(M3, 256, 3, name='P3')\n",
        "      pyrammid_features = [P7, P6, P5, P4, P3]\n",
        "\n",
        "      classification_subnet = build_classification_subnet(n_classes=n_classes)\n",
        "      regression_subnet = build_regression_subnet()\n",
        "\n",
        "      classification_outputs = [classification_subnet(\n",
        "          level) for level in pyrammid_features]\n",
        "      regression_outputs = [regression_subnet(\n",
        "          level) for level in pyrammid_features]\n",
        "\n",
        "      classification_head = tf.keras.layers.concatenate(\n",
        "          classification_outputs, axis=1, name='classification_head')\n",
        "      regression_head = tf.keras.layers.concatenate(\n",
        "          regression_outputs, axis=1, name='regression_head')\n",
        "\n",
        "      image_input = base_model.input\n",
        "      classification_targets = tf.keras.layers.Input(shape=[num_anchors])\n",
        "      regression_targets = tf.keras.layers.Input(shape=[num_anchors, 4])\n",
        "      background_mask = tf.keras.layers.Input(shape=[num_anchors])\n",
        "      ignore_mask = tf.keras.layers.Input(shape=[num_anchors])\n",
        "\n",
        "\n",
        "      Lreg, Lcls, _ = tf.keras.layers.Lambda(loss_fn)([classification_targets,\n",
        "                              classification_head,\n",
        "                              regression_targets,\n",
        "                              regression_head,\n",
        "                              background_mask,\n",
        "                              ignore_mask])\n",
        "\n",
        "      Lreg = tf.keras.layers.Lambda(lambda x : tf.reshape(x, [-1, 1]), name='box')(Lreg)\n",
        "      Lcls = tf.keras.layers.Lambda(lambda x : tf.reshape(x, [-1, 1]), name='focal')(Lcls)\n",
        "\n",
        "      if training:\n",
        "          _inputs = [image_input, classification_targets, regression_targets, background_mask, ignore_mask]\n",
        "          _outputs = [Lreg, Lcls]\n",
        "      else:\n",
        "          _inputs = [image_input]\n",
        "          _outputs = [classification_head, regression_head]\n",
        "      return tf.keras.Model(inputs=_inputs, outputs=_outputs, name='RetinaNet')\n",
        "    \n",
        "  model = RetinaNet(input_shape=INPUT_SHAPE, n_classes=N_CLASSES, training=True)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=LR, clipnorm=0.001)\n",
        "\n",
        "  loss_dict = {\n",
        "      'box': lambda x, y: y,\n",
        "      'focal': lambda x, y: y\n",
        "  }\n",
        "  callback_list = [\n",
        "      tf.keras.callbacks.TensorBoard(log_dir='gs://srihari-datasets/retinanet/logs', update_freq='epoch'),\n",
        "      tf.keras.callbacks.ModelCheckpoint('gs://srihari-datasets/retinanet/weights.{epoch:02d}',\n",
        "                                         save_weights_only=True,\n",
        "                                         save_best_only=True, monitor='loss')\n",
        "  ]\n",
        "  model.compile(optimizer=optimizer, loss=loss_dict)\n",
        "  model.fit(train_dataset,\n",
        "            epochs=200,\n",
        "            steps_per_epoch=training_steps,\n",
        "            validation_data=val_dataset,\n",
        "            validation_steps=val_steps,\n",
        "            validation_freq=25, \n",
        "            callbacks=callback_list)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "W0901 16:21:31.505701 139673780430720 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0901 16:21:32.579859 139673780430720 deprecation.py:323] From <ipython-input-2-bc4ddc108b24>:332: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0901 16:23:23.233881 139673780430720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py:411: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            " 2/39 [>.............................] - ETA: 14:39 - loss: 4.2564 - box_loss: 3.1065 - focal_loss: 1.1499"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0901 16:24:10.758876 139673780430720 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (1.136326). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "39/39 [==============================] - 95s 2s/step - loss: 3.9764 - box_loss: 2.9759 - focal_loss: 1.0005\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 36s 913ms/step - loss: 3.7954 - box_loss: 2.9106 - focal_loss: 0.8849\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 35s 888ms/step - loss: 3.7533 - box_loss: 2.8926 - focal_loss: 0.8607\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 35s 909ms/step - loss: 3.6949 - box_loss: 2.8496 - focal_loss: 0.8452\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 34s 876ms/step - loss: 3.6205 - box_loss: 2.7887 - focal_loss: 0.8318\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 40s 1s/step - loss: 3.5624 - box_loss: 2.7394 - focal_loss: 0.8230\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 36s 934ms/step - loss: 3.5217 - box_loss: 2.7067 - focal_loss: 0.8150\n",
            "Epoch 8/200\n",
            "39/39 [==============================] - 35s 890ms/step - loss: 3.4843 - box_loss: 2.6767 - focal_loss: 0.8076\n",
            "Epoch 9/200\n",
            "39/39 [==============================] - 35s 893ms/step - loss: 3.4534 - box_loss: 2.6516 - focal_loss: 0.8018\n",
            "Epoch 10/200\n",
            "39/39 [==============================] - 69s 2s/step\n",
            "39/39 [==============================] - 69s 2s/step\n",
            "39/39 [==============================] - 131s 3s/step - loss: 3.4192 - box_loss: 2.6219 - focal_loss: 0.7973 - val_loss: 3.6045 - val_box_loss: 2.7067 - val_focal_loss: 0.8978\n",
            "Epoch 11/200\n",
            "39/39 [==============================] - 36s 916ms/step - loss: 3.3946 - box_loss: 2.6002 - focal_loss: 0.7944\n",
            "Epoch 12/200\n",
            "39/39 [==============================] - 33s 848ms/step - loss: 3.3609 - box_loss: 2.5711 - focal_loss: 0.7898\n",
            "Epoch 13/200\n",
            "39/39 [==============================] - 36s 921ms/step - loss: 3.3273 - box_loss: 2.5441 - focal_loss: 0.7831\n",
            "Epoch 14/200\n",
            "39/39 [==============================] - 36s 917ms/step - loss: 3.3015 - box_loss: 2.5192 - focal_loss: 0.7822\n",
            "Epoch 15/200\n",
            "39/39 [==============================] - 35s 899ms/step - loss: 3.2689 - box_loss: 2.4912 - focal_loss: 0.7777\n",
            "Epoch 16/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e789c9104275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             callbacks=callback_list)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m             validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     batch_size = self._validate_or_infer_batch_size(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mfit_distributed\u001b[0;34m(model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m    129\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return training_arrays.fit_loop(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mexperimental_tpu_fit_loop\u001b[0;34m(model, dataset, epochs, verbose, callbacks, initial_epoch, steps_per_epoch, val_dataset, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mprev_step_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         logging.warning('Your dataset iterator ran out of data; '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   3008\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3010\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3011\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3012\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rr7Y2cVaBrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGw6iodcjb-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}