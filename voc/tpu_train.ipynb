{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "tpu_train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahvQZWQSfoEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "89f1df43-330c-439a-e7ec-75f05f6bfd8c"
      },
      "source": [
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('Tensorflow', tf.__version__)\n",
        "\n",
        "\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.config.experimental_connect_to_host(cluster_resolver.get_master())\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
        "base_path = 'gs:/srihari-datasets'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow 1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0901 16:14:58.503292 140303241430912 tpu_strategy_util.py:56] TPU system %s has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpWHjvU-foEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  def imshow(image):\n",
        "      plt.figure(figsize=(12, 12))\n",
        "      plt.axis('off')\n",
        "      plt.imshow(image)\n",
        "\n",
        "\n",
        "  def compute_anchor_dimensions(ratios=[0.5, 1, 2],\n",
        "                                scales=[1, 1.25, 1.58],\n",
        "                                areas=[32 * 32, 64 * 64, 128 * 128, 256 * 256, 512 * 512]):\n",
        "      anchor_shapes = {'P{}'.format(i): [] for i in range(3, 8)}\n",
        "      for area in areas:\n",
        "          for ratio in ratios:\n",
        "              a_h = np.sqrt(area / ratio)\n",
        "              a_w = area / a_h\n",
        "              for scale in scales:\n",
        "                  h = np.int32(scale * a_h)\n",
        "                  w = np.int32(scale * a_w)\n",
        "                  anchor_shapes['P{}'.format(\n",
        "                      int(np.log2(np.sqrt(area) // 4)))].append([w, h])\n",
        "          anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))] = np.array(\n",
        "              anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))])\n",
        "      return anchor_shapes\n",
        "\n",
        "\n",
        "  def get_anchors(input_shape=512, tensor=True):\n",
        "      anchor_dimensions = compute_anchor_dimensions()\n",
        "      anchors = []\n",
        "      for i in range(3, 8):\n",
        "          feature_name = 'P{}'.format(i)\n",
        "          stride = 2**i\n",
        "          feature_size = (input_shape) // stride\n",
        "\n",
        "          dims = anchor_dimensions[feature_name]\n",
        "          dims = dims[None, None, ...]\n",
        "          dims = np.tile(dims, reps=[feature_size, feature_size, 1, 1])\n",
        "\n",
        "          rx = (np.arange(feature_size) + 0.5) * (stride)\n",
        "          ry = (np.arange(feature_size) + 0.5) * (stride)\n",
        "          sx, sy = np.meshgrid(rx, ry)\n",
        "          cxy = np.stack([sx, sy], axis=-1)\n",
        "          cxy = cxy[:, :, None, :]\n",
        "          cxy = np.tile(cxy, reps=[1, 1, 9, 1])\n",
        "          anchors.append(np.reshape(\n",
        "              np.concatenate([cxy, dims], axis=-1), [-1, 4]))\n",
        "      anchors = np.concatenate(anchors, axis=0)\n",
        "      if tensor:\n",
        "          anchors = tf.constant(anchors, dtype=tf.float32)\n",
        "      return anchors\n",
        "\n",
        "\n",
        "  @tf.function()\n",
        "  def compute_iou(boxes1, boxes2):\n",
        "      boxes1 = tf.cast(boxes1, dtype=tf.float32)\n",
        "      boxes2 = tf.cast(boxes2, dtype=tf.float32)\n",
        "\n",
        "      boxes1_t = change_box_format(boxes1, return_format='x1y1x2y2')\n",
        "      boxes2_t = change_box_format(boxes2, return_format='x1y1x2y2')\n",
        "\n",
        "      lu = tf.maximum(boxes1_t[:, None, :2], boxes2_t[:, :2])\n",
        "      rd = tf.minimum(boxes1_t[:, None, 2:], boxes2_t[:, 2:])\n",
        "\n",
        "      intersection = tf.maximum(0.0, rd - lu)\n",
        "      inter_square = intersection[:, :, 0] * intersection[:, :, 1]\n",
        "\n",
        "      square1 = boxes1[:, 2] * boxes1[:, 3]\n",
        "      square2 = boxes2[:, 2] * boxes2[:, 3]\n",
        "\n",
        "      union_square = tf.maximum(square1[:, None] + square2 - inter_square, 1e-10)\n",
        "      return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)\n",
        "\n",
        "\n",
        "  def change_box_format(boxes, return_format='xywh'):\n",
        "      boxes = tf.cast(boxes, dtype=tf.float32)\n",
        "      if return_format == 'xywh':\n",
        "\n",
        "          return tf.stack([(boxes[..., 2] + boxes[..., 0]) / 2.0,\n",
        "                           (boxes[..., 3] + boxes[..., 1]) / 2.0,\n",
        "                           boxes[..., 2] - boxes[..., 0],\n",
        "                           boxes[..., 3] - boxes[..., 1]], axis=-1)\n",
        "      elif return_format == 'x1y1x2y2':\n",
        "\n",
        "          return tf.stack([boxes[..., 0] - boxes[..., 2] / 2.0,\n",
        "                           boxes[..., 1] - boxes[..., 3] / 2.0,\n",
        "                           boxes[..., 0] + boxes[..., 2] / 2.0,\n",
        "                           boxes[..., 1] + boxes[..., 3] / 2.0], axis=-1)\n",
        "      return 'You should not be here'\n",
        "\n",
        "\n",
        "  def draw_bboxes(image, bbox_list):\n",
        "      image = image / 255.\n",
        "      h, w = image.shape.as_list()[:2]\n",
        "      bboxes = tf.cast(tf.stack([\n",
        "          bbox_list[:, 1] / h, bbox_list[:, 0] /\n",
        "          w, bbox_list[:, 3] / h, bbox_list[:, 2] / w\n",
        "      ], axis=-1), dtype=tf.float32)\n",
        "\n",
        "      colors = tf.random.uniform(maxval=1, shape=[bbox_list.shape[0], 3])\n",
        "      return tf.image.convert_image_dtype(tf.image.draw_bounding_boxes(image[None, ...],\n",
        "                                                                       bboxes[None, ...],\n",
        "                                                                       colors)[0, ...], dtype=tf.uint8)\n",
        "\n",
        "\n",
        "  def draw_boxes_cv2(image, bbox_list):\n",
        "      img = np.uint8(image).copy()\n",
        "      bbox_list = np.array(bbox_list, dtype=np.int32)\n",
        "      for box in bbox_list:\n",
        "          img = cv2.rectangle(img, (box[0], box[1]),\n",
        "                              (box[2], box[3]), [0, 0, 200], 3)\n",
        "      return img\n",
        "\n",
        "\n",
        "  def get_label(label_path, class_map, input_shape=512):\n",
        "      with open(label_path, 'r') as f:\n",
        "          temp = json.load(f)\n",
        "      bbox = []\n",
        "      class_ids = []\n",
        "      for obj in temp['frames'][0]['objects']:\n",
        "          if 'box2d' in obj:\n",
        "              x1 = obj['box2d']['x1']\n",
        "              y1 = obj['box2d']['y1']\n",
        "              x2 = obj['box2d']['x2']\n",
        "              y2 = obj['box2d']['y2']\n",
        "              bbox.append(np.array([x1, y1, x2, y2]))\n",
        "              class_ids.append(class_map[obj['category']])\n",
        "      bbox = np.array(bbox, dtype=np.float32)\n",
        "      H, W = 720, 1280.\n",
        "      bbox[:, 0] = bbox[:, 0] / W\n",
        "      bbox[:, 2] = bbox[:, 2] / W\n",
        "      bbox[:, 1] = bbox[:, 1] / H\n",
        "      bbox[:, 3] = bbox[:, 3] / H\n",
        "      bbox = np.int32(bbox * input_shape)\n",
        "      class_ids = np.array(class_ids, dtype=np.float32)[..., None]\n",
        "      return np.concatenate([bbox, class_ids], axis=-1)\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def get_image(image_path, input_shape=None):\n",
        "      H = W = input_shape\n",
        "      img = tf.io.read_file(image_path)\n",
        "      img = tf.image.decode_jpeg(img)\n",
        "      img = tf.image.resize(img, size=[H, W])\n",
        "      img = img[:, :, ::-1] - tf.constant([103.939, 116.779, 123.68])\n",
        "      return img\n",
        "\n",
        "\n",
        "  def load_data(input_shape=None):\n",
        "      def load_data(image_path, label):\n",
        "          images = get_image(image_path, input_shape=input_shape)\n",
        "          targets = encode_targets(label, input_shape=input_shape)\n",
        "\n",
        "          return images, targets\n",
        "      return load_data\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def encode_targets(label, input_shape=None):\n",
        "      \"\"\"We use the assignment rule from RPN.\n",
        "          Faster RCNN box coder follows the coding schema described below:\n",
        "              ty = (y - ya) / ha\n",
        "              tx = (x - xa) / wa\n",
        "              th = log(h / ha)\n",
        "              tw = log(w / wa)\n",
        "          where x, y, w, h denote the box's center coordinates, width and height\n",
        "          respectively. Similarly, xa, ya, wa, ha denote the anchor's center\n",
        "          coordinates, width and height. tx, ty, tw and th denote the\n",
        "          anchor-encoded center, width and height respectively.\n",
        "          The open-source implementation recommends using [10.0, 10.0, 5.0, 5.0] as\n",
        "          scale factors.\n",
        "          See http://arxiv.org/abs/1506.01497 for details. \n",
        "          Set achors with iou < 0.5 to 0 and\n",
        "          set achors with iou iou > 0.4 && < 0.5 to -1. Convert\n",
        "          regression targets into one-hot encoding (N, \n",
        "          in loss_fn and exclude background class in loss calculation.\n",
        "          Use [0, 0, 0, ... 0, n_classes] (all units set to zeros) to represent\n",
        "          background class.\n",
        "      \"\"\"\n",
        "      scale_factors = tf.constant([5.0, 5.0, 5.0, 5.0])\n",
        "      anchors = get_anchors(input_shape=input_shape, tensor=True)\n",
        "      gt_boxes = label[:, :4]\n",
        "      gt_boxes = change_box_format(gt_boxes, return_format='xywh')\n",
        "      gt_class_ids = label[:, 4]\n",
        "      ious = compute_iou(anchors, gt_boxes)\n",
        "\n",
        "      max_ious = tf.reduce_max(ious, axis=1)\n",
        "      max_ids = tf.argmax(ious, axis=1, output_type=tf.int32)\n",
        "\n",
        "      background_mask = max_ious > 0.5\n",
        "      ignore_mask = tf.logical_and(max_ious > 0.4, max_ious < 0.5)\n",
        "\n",
        "      selected_gt_boxes = tf.gather(gt_boxes, max_ids)\n",
        "      selected_gt_class_ids = 1. + tf.gather(gt_class_ids, max_ids)\n",
        "\n",
        "      selected_gt_class_ids = selected_gt_class_ids * \\\n",
        "          tf.cast(background_mask, dtype=tf.float32)\n",
        "      classification_targets = selected_gt_class_ids - tf.cast(\n",
        "          ignore_mask, dtype=tf.float32)\n",
        "      regression_targets = tf.stack([\n",
        "          (selected_gt_boxes[:, 0] - anchors[:, 0]) / anchors[:, 2],\n",
        "          (selected_gt_boxes[:, 1] - anchors[:, 1]) / anchors[:, 3],\n",
        "          tf.math.log(selected_gt_boxes[:, 2] / anchors[:, 2]),\n",
        "          tf.math.log(selected_gt_boxes[:, 3] / anchors[:, 3])\n",
        "      ], axis=-1)\n",
        "      regression_targets = regression_targets * scale_factors\n",
        "      return (tf.cast(classification_targets, dtype=tf.int32),\n",
        "              regression_targets,\n",
        "              background_mask,\n",
        "              ignore_mask)\n",
        "\n",
        "\n",
        "  def decode_targets(classification_outputs,\n",
        "                     regression_outputs,\n",
        "                     input_shape=512,\n",
        "                     classification_threshold=0.05,\n",
        "                     nms_threshold=0.5):\n",
        "      scale_factors = tf.constant([5.0, 5.0, 5.0, 5.0])\n",
        "      anchors = get_anchors(input_shape=input_shape, tensor=True)\n",
        "\n",
        "      '''gt targets are in one hot form, no need to apply  sigmoid to check correctness, use sigmoid during actual inference'''\n",
        "      class_ids = tf.argmax(classification_outputs, axis=-1)\n",
        "\n",
        "      confidence_scores = tf.reduce_max(\n",
        "          tf.nn.sigmoid(classification_outputs), axis=-1)\n",
        "      regression_outputs = regression_outputs / scale_factors\n",
        "      boxes = tf.concat([(regression_outputs[:, :2] * anchors[:, 2:] + anchors[:, :2]),\n",
        "                         tf.math.exp(regression_outputs[:, 2:]) * anchors[:, 2:]\n",
        "                         ], axis=-1)\n",
        "      boxes = change_box_format(boxes, return_format='x1y1x2y2')\n",
        "\n",
        "      nms_indices = tf.image.non_max_suppression(boxes,\n",
        "                                                 confidence_scores,\n",
        "                                                 score_threshold=classification_threshold,\n",
        "                                                 iou_threshold=nms_threshold,\n",
        "                                                 max_output_size=200)\n",
        "      final_class_ids = tf.gather(class_ids, nms_indices)\n",
        "      final_scores = tf.gather(confidence_scores, nms_indices)\n",
        "      final_boxes = tf.cast(tf.gather(boxes, nms_indices), dtype=tf.int32)\n",
        "\n",
        "      matched_anchors = tf.gather(anchors, tf.where(\n",
        "          confidence_scores > classification_threshold)[:, 0])\n",
        "      matched_anchors = tf.cast(change_box_format(matched_anchors, return_format='x1y1x2y2'),\n",
        "                                dtype=tf.int32)\n",
        "      return final_boxes, final_class_ids, final_scores, matched_anchors\n",
        "\n",
        "\n",
        "  def conv_block(x,\n",
        "                 n_filters,\n",
        "                 size,\n",
        "                 strides=1,\n",
        "                 kernel_init='he_normal',\n",
        "                 bias_init='zeros',\n",
        "                 bn_activated=False, name=''):\n",
        "      x = tf.keras.layers.Conv2D(filters=n_filters,\n",
        "                                 kernel_size=size,\n",
        "                                 padding='same',\n",
        "                                 strides=strides,\n",
        "                                 kernel_initializer=kernel_init,\n",
        "                                 bias_initializer=bias_init,\n",
        "                                 name='conv_' + name if name else None)(x)\n",
        "      if bn_activated:\n",
        "          x = tf.keras.layers.BatchNormalization()(x)\n",
        "          x = tf.keras.layers.ReLU()(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "  def Upsampling(tensor, scale=2):\n",
        "      dims = tensor.shape.as_list()[1:-1]\n",
        "      return tf.image.resize_bilinear(tensor, size=[dims[0] * scale, dims[1] * scale], align_corners=True)\n",
        "\n",
        "\n",
        "  def build_classification_subnet(n_classes=None, n_anchors=9, p=0.01):\n",
        "      input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
        "      x = input_layer\n",
        "      for i in range(4):\n",
        "          x = conv_block(\n",
        "              x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
        "          x = tf.keras.layers.ReLU()(x)\n",
        "      bias_init = -np.log((1 - p) / p)\n",
        "      output_layer = tf.keras.layers.Conv2D(filters=n_classes * n_anchors,\n",
        "                                            kernel_size=3,\n",
        "                                            padding='same',\n",
        "                                            kernel_initializer=tf.keras.initializers.RandomNormal(\n",
        "                                                0.0, 0.01),\n",
        "                                            bias_initializer=tf.keras.initializers.Constant(\n",
        "                                                value=bias_init),\n",
        "                                            activation=None)(x)\n",
        "      output_layer = tf.keras.layers.Reshape(\n",
        "          target_shape=[-1, n_classes])(output_layer)\n",
        "      return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='classification_subnet')\n",
        "\n",
        "\n",
        "  def build_regression_subnet(n_anchors=9):\n",
        "      input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
        "      x = input_layer\n",
        "      for i in range(4):\n",
        "          x = conv_block(\n",
        "              x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
        "          x = tf.keras.layers.ReLU()(x)\n",
        "      output_layer = tf.keras.layers.Conv2D(filters=4 * n_anchors,\n",
        "                                            kernel_size=3,\n",
        "                                            padding='same',\n",
        "                                            kernel_initializer=tf.keras.initializers.RandomNormal(\n",
        "                                                0.0, 0.01),\n",
        "                                            bias_initializer=tf.keras.initializers.zeros(),\n",
        "                                            activation=None)(x)\n",
        "      output_layer = tf.keras.layers.Reshape(target_shape=[-1, 4])(output_layer)\n",
        "      return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='regression_subnet')\n",
        "\n",
        "\n",
        "  class LossV2():\n",
        "      def __init__(self, batch_size=None, n_classes=None):\n",
        "          self.num_classes = n_classes\n",
        "          self.global_batch_size = batch_size\n",
        "\n",
        "      def focal_loss(self, y_true, y_pred, alpha=0.25, gamma=2):\n",
        "          y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32), depth=self.num_classes + 1)\n",
        "          y_true = y_true[:, :, 1:]\n",
        "          y_pred = tf.sigmoid(y_pred)\n",
        "\n",
        "          at = alpha * y_true + (1 - y_true) * (1 - alpha)\n",
        "          pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "          f_loss = -at * tf.pow(1 - pt, gamma) * tf.math.log(pt)\n",
        "          return f_loss\n",
        "\n",
        "      def smooth_l1(self, y_true, y_pred, sigma=3.0):\n",
        "          y_true = tf.cast(y_true, dtype=y_pred.dtype)\n",
        "          sigma = tf.cast(sigma, dtype=y_pred.dtype)\n",
        "          x = y_true - y_pred\n",
        "          abs_x = tf.abs(x)\n",
        "          sigma_squared = tf.square(sigma)\n",
        "          quadratic = 0.5 * tf.square(sigma * x)\n",
        "          linear = abs_x - (0.5 / sigma_squared)\n",
        "          smooth_l1_loss = tf.where(tf.less(abs_x, 1./sigma_squared), quadratic, linear)\n",
        "          return smooth_l1_loss\n",
        "\n",
        "      def __call__(self, tensor):\n",
        "          classification_targets = tensor[0]\n",
        "          classification_predictions = tensor[1]\n",
        "          regression_targets = tensor[2]\n",
        "          regression_predictions = tensor[3]\n",
        "          background_mask = tensor[4]\n",
        "          ignore_mask = tensor[5]\n",
        "          \n",
        "          background_mask = tf.cast(background_mask, dtype=tf.bool, name='bg_cast')\n",
        "          ignore_mask = tf.cast(ignore_mask, dtype=tf.bool, name='ig_cast')\n",
        "\n",
        "          num_positive_detections = tf.maximum(tf.reduce_sum(\n",
        "              tf.cast(background_mask, dtype=tf.float32), axis=-1), 1.0)\n",
        "#           num_positive_detections = tf.maximum(tf.reduce_sum(\n",
        "#               background_mask, axis=-1), 1.0)\n",
        "              \n",
        "          positive_classification_mask = tf.expand_dims(\n",
        "              tf.logical_not(ignore_mask), axis=-1)\n",
        "          positive_classification_mask = tf.tile(\n",
        "              positive_classification_mask, multiples=[1, 1, self.num_classes])\n",
        "\n",
        "          positive_regression_mask = tf.expand_dims(background_mask, axis=-1)\n",
        "          positive_regression_mask = tf.tile(\n",
        "              positive_regression_mask, multiples=[1, 1, 4])\n",
        "\n",
        "          Lcls = self.focal_loss(classification_targets,\n",
        "                                 classification_predictions)\n",
        "          Lreg = self.smooth_l1(regression_targets, regression_predictions)\n",
        "          Lcls = Lcls * tf.cast(positive_classification_mask, dtype=tf.float32)\n",
        "          Lreg = Lreg * tf.cast(positive_regression_mask, dtype=tf.float32)\n",
        "\n",
        "          Lcls = tf.reduce_sum(\n",
        "              Lcls, axis=[1, 2]) / num_positive_detections\n",
        "          Lreg = tf.reduce_sum(\n",
        "              Lreg, axis=[1, 2]) / num_positive_detections\n",
        "\n",
        "          Lcls = tf.reduce_mean(Lcls)\n",
        "          Lreg = tf.reduce_mean(Lreg)\n",
        "          return Lreg, Lcls, tf.reduce_mean(num_positive_detections)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_aGcRv6foEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_SHAPE = 640\n",
        "BATCH_SIZE = 64\n",
        "N_CLASSES = 20\n",
        "EPOCHS = 200\n",
        "training_steps = 2501 // BATCH_SIZE\n",
        "val_steps = 2510 // BATCH_SIZE\n",
        "LR = 1e-5 * BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqxKuvBefoEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  @tf.function\n",
        "  def flip_data(image, boxes, w):\n",
        "      if tf.random.uniform(()) > 0.5:\n",
        "          image = tf.image.flip_left_right(image)\n",
        "          boxes = tf.stack([\n",
        "              w - boxes[:, 2],\n",
        "              boxes[:, 1],\n",
        "              w - boxes[:, 0],\n",
        "              boxes[:, 3]\n",
        "          ], axis=-1)\n",
        "      return image, boxes\n",
        "\n",
        "\n",
        "  def load_data(input_shape):\n",
        "      h, w = input_shape, input_shape\n",
        "\n",
        "      @tf.function\n",
        "      def load_data_(example, input_shape=input_shape):\n",
        "          image = tf.cast(example['image'], dtype=tf.float32)\n",
        "          boxes_ = example['objects']['bbox']\n",
        "          class_ids = tf.expand_dims(\n",
        "              tf.cast(example['objects']['label'], dtype=tf.float32), axis=-1)\n",
        "          image = tf.image.resize(image, size=[h, w])\n",
        "\n",
        "          boxes = tf.stack([\n",
        "              tf.clip_by_value(boxes_[:, 1] * w, 0, w),\n",
        "              tf.clip_by_value(boxes_[:, 0] * h, 0, h),\n",
        "              tf.clip_by_value(boxes_[:, 3] * w, 0, w),\n",
        "              tf.clip_by_value(boxes_[:, 2] * h, 0, h)\n",
        "          ], axis=-1)\n",
        "          image, boxes = flip_data(image, boxes, w)\n",
        "          label = tf.concat([boxes, class_ids], axis=-1)\n",
        "          cls_targets, reg_targets, bg, ig = encode_targets(\n",
        "              label, input_shape=input_shape)\n",
        "          bg = tf.cast(bg, dtype=tf.float32)\n",
        "          ig = tf.cast(ig, dtype=tf.float32)\n",
        "          cls_targets = tf.cast(cls_targets, dtype=tf.float32)\n",
        "          return (image, cls_targets, reg_targets, bg, ig), (tf.ones((1, )), tf.ones((1, )))\n",
        "      return load_data_\n",
        "\n",
        "\n",
        "  train_dataset = tfds.load('voc2007', data_dir='gs://srihari-datasets/', shuffle_files=False, split=['train'])[0]\n",
        "  train_dataset = train_dataset.map(load_data(\n",
        "      input_shape=INPUT_SHAPE), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
        "  train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  val_dataset = tfds.load('voc2007', data_dir='gs://srihari-datasets/', shuffle_files=False,\n",
        "                          split=['validation'])[0]\n",
        "  val_dataset = val_dataset.map(load_data(\n",
        "      input_shape=INPUT_SHAPE), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
        "  val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  train_dataset, val_dataset\n",
        "\n",
        "\n",
        "  # i = 0\n",
        "  # for batch in train_dataset.take(1):\n",
        "  #     break\n",
        "  # image, cls_targets, reg_targets, _, _ = batch[0]\n",
        "  # classification_outputs = tf.one_hot(tf.cast(cls_targets[i], dtype=tf.int32), depth=N_CLASSES + 1)[:, 1:]\n",
        "  # regression_outputs = reg_targets[i]\n",
        "  # image = image[i]\n",
        "  # scale_factors = tf.constant([5.0, 5.0, 5.0, 5.0])\n",
        "  # anchors = get_anchors(input_shape=INPUT_SHAPE, tensor=True)\n",
        "  # class_ids = tf.argmax(classification_outputs, axis=-1)\n",
        "  # confidence_scores = tf.reduce_max(classification_outputs, axis=-1)\n",
        "  # regression_outputs = regression_outputs / scale_factors\n",
        "  # boxes = tf.concat([(regression_outputs[:, :2] * anchors[:, 2:] + anchors[:, :2]),\n",
        "  #                    tf.math.exp(regression_outputs[:, 2:]) * anchors[:, 2:]\n",
        "  #                    ], axis=-1)\n",
        "  # boxes = change_box_format(boxes, return_format='x1y1x2y2')\n",
        "\n",
        "  # nms_indices = tf.image.non_max_suppression(boxes,\n",
        "  #                                            confidence_scores,\n",
        "  #                                            score_threshold=0.05,\n",
        "  #                                            iou_threshold=0.5,\n",
        "  #                                            max_output_size=200)\n",
        "  # final_class_ids = tf.gather(class_ids, nms_indices)\n",
        "  # final_scores = tf.gather(confidence_scores, nms_indices)\n",
        "  # final_boxes = tf.cast(tf.gather(boxes, nms_indices), dtype=tf.int32)\n",
        "\n",
        "  # matched_anchors = tf.gather(anchors, tf.where(confidence_scores > 0.05)[:, 0])\n",
        "  # matched_anchors = tf.cast(change_box_format(matched_anchors, return_format='x1y1x2y2'),\n",
        "  #                           dtype=tf.int32)\n",
        "  # img = draw_boxes_cv2(image, boxes)\n",
        "  # imshow(img)\n",
        "  # print(final_boxes.numpy())\n",
        "  # print(final_class_ids.numpy())\n",
        "  # print(final_scores.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5n59juRfoEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e8c3419-c494-4ed9-8d78-afd2d716a5b1"
      },
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  def RetinaNet(input_shape=None, n_classes=None, training=False):\n",
        "      H = W = input_shape\n",
        "      num_anchors = get_anchors(input_shape=H).shape[0]\n",
        "      loss_fn = LossV2(batch_size=BATCH_SIZE, n_classes=N_CLASSES)\n",
        "\n",
        "      base_model = tf.keras.applications.ResNet50(\n",
        "          input_shape=[H, W, 3], weights=None, include_top=False)\n",
        "\n",
        "      resnet_block_output_names = ['activation_21', 'activation_39', 'activation_48']\n",
        "\n",
        "      resnet_block_outputs = {'C{}'.format(idx + 3): base_model.get_layer(\n",
        "          layer).output for idx, layer in enumerate(resnet_block_output_names)}\n",
        "      resnet_block_outputs = {level: conv_block(\n",
        "          tensor, 256, 1, name=level + '_1x1') for level, tensor in resnet_block_outputs.items()}\n",
        "\n",
        "      P5 = resnet_block_outputs['C5']\n",
        "      P6 = conv_block(base_model.get_layer(\n",
        "          'activation_48').output, 256, 3, strides=2, name='P6')\n",
        "      P6_relu = tf.keras.layers.ReLU(name='P6')(P6)\n",
        "      P7 = conv_block(P6_relu, 256, 3, strides=2, name='P7')\n",
        "      M4 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2}, name='P5_UP')(\n",
        "          P5), resnet_block_outputs['C4']], name='P4_merge')\n",
        "      M3 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2}, name='P4_UP')(\n",
        "          M4), resnet_block_outputs['C3']], name='P3_merge')\n",
        "      P4 = conv_block(M4, 256, 3, name='P4')\n",
        "      P3 = conv_block(M3, 256, 3, name='P3')\n",
        "      pyrammid_features = [P7, P6, P5, P4, P3]\n",
        "\n",
        "      classification_subnet = build_classification_subnet(n_classes=n_classes)\n",
        "      regression_subnet = build_regression_subnet()\n",
        "\n",
        "      classification_outputs = [classification_subnet(\n",
        "          level) for level in pyrammid_features]\n",
        "      regression_outputs = [regression_subnet(\n",
        "          level) for level in pyrammid_features]\n",
        "\n",
        "      classification_head = tf.keras.layers.concatenate(\n",
        "          classification_outputs, axis=1, name='classification_head')\n",
        "      regression_head = tf.keras.layers.concatenate(\n",
        "          regression_outputs, axis=1, name='regression_head')\n",
        "\n",
        "      image_input = base_model.input\n",
        "      classification_targets = tf.keras.layers.Input(shape=[num_anchors])\n",
        "      regression_targets = tf.keras.layers.Input(shape=[num_anchors, 4])\n",
        "      background_mask = tf.keras.layers.Input(shape=[num_anchors])\n",
        "      ignore_mask = tf.keras.layers.Input(shape=[num_anchors])\n",
        "\n",
        "\n",
        "      Lreg, Lcls, _ = tf.keras.layers.Lambda(loss_fn)([classification_targets,\n",
        "                              classification_head,\n",
        "                              regression_targets,\n",
        "                              regression_head,\n",
        "                              background_mask,\n",
        "                              ignore_mask])\n",
        "\n",
        "      Lreg = tf.keras.layers.Lambda(lambda x : tf.reshape(x, [-1, 1]), name='box')(Lreg)\n",
        "      Lcls = tf.keras.layers.Lambda(lambda x : tf.reshape(x, [-1, 1]), name='focal')(Lcls)\n",
        "\n",
        "      if training:\n",
        "          _inputs = [image_input, classification_targets, regression_targets, background_mask, ignore_mask]\n",
        "          _outputs = [Lreg, Lcls]\n",
        "      else:\n",
        "          _inputs = [image_input]\n",
        "          _outputs = [classification_head, regression_head]\n",
        "      return tf.keras.Model(inputs=_inputs, outputs=_outputs, name='RetinaNet')\n",
        "    \n",
        "  model = RetinaNet(input_shape=INPUT_SHAPE, n_classes=N_CLASSES, training=True)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=LR, clipnorm=0.001)\n",
        "\n",
        "  loss_dict = {\n",
        "      'box': lambda x, y: y,\n",
        "      'focal': lambda x, y: y\n",
        "  }\n",
        "  callback_list = [\n",
        "      tf.keras.callbacks.TensorBoard(log_dir=base_path+'/logs', update_freq='epoch'),\n",
        "      tf.keras.callbacks.ModelCheckpoint(base_path+'/weights.{epoch:02d}', save_weights_only=True)\n",
        "  ]\n",
        "  model.compile(optimizer=optimizer, loss=loss_dict)\n",
        "  model.fit(train_dataset,\n",
        "            epochs=200,\n",
        "            steps_per_epoch=training_steps,\n",
        "            validation_data=val_dataset,\n",
        "            validation_steps=val_steps,\n",
        "            validation_freq=10, \n",
        "            callbacks=callback_list)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "W0901 15:40:34.287770 140303241430912 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0901 15:40:35.357016 140303241430912 deprecation.py:323] From <ipython-input-2-bc4ddc108b24>:332: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0901 15:42:15.348943 140303241430912 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py:411: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "39/39 [==============================] - 65s 2s/step\n",
            "39/39 [==============================] - 65s 2s/step\n",
            "39/39 [==============================] - 153s 4s/step - loss: 3.9750 - box_loss: 2.9756 - focal_loss: 0.9994 - val_loss: nan - val_box_loss: 7.3175 - val_focal_loss: nan\n",
            "Epoch 2/200\n",
            "39/39 [==============================] - 69s 2s/step\n",
            "39/39 [==============================] - 69s 2s/step\n",
            "39/39 [==============================] - 116s 3s/step - loss: 3.7914 - box_loss: 2.9098 - focal_loss: 0.8816 - val_loss: 4.6861 - val_box_loss: 3.1455 - val_focal_loss: 1.5406\n",
            "Epoch 3/200\n",
            "39/39 [==============================] - 72s 2s/step\n",
            "39/39 [==============================] - 72s 2s/step\n",
            "39/39 [==============================] - 119s 3s/step - loss: 3.7521 - box_loss: 2.8925 - focal_loss: 0.8597 - val_loss: 3.8929 - val_box_loss: 2.9278 - val_focal_loss: 0.9651\n",
            "Epoch 4/200\n",
            "39/39 [==============================] - 78s 2s/step\n",
            "39/39 [==============================] - 78s 2s/step\n",
            "39/39 [==============================] - 130s 3s/step - loss: 3.6966 - box_loss: 2.8511 - focal_loss: 0.8455 - val_loss: 3.8735 - val_box_loss: 2.8872 - val_focal_loss: 0.9864\n",
            "Epoch 5/200\n",
            "39/39 [==============================] - 81s 2s/step\n",
            "39/39 [==============================] - 81s 2s/step\n",
            "39/39 [==============================] - 133s 3s/step - loss: 3.6331 - box_loss: 2.7991 - focal_loss: 0.8339 - val_loss: 3.8853 - val_box_loss: 2.7985 - val_focal_loss: 1.0868\n",
            "Epoch 6/200\n",
            "39/39 [==============================] - 83s 2s/step\n",
            "39/39 [==============================] - 83s 2s/step\n",
            "39/39 [==============================] - 137s 4s/step - loss: 3.5700 - box_loss: 2.7491 - focal_loss: 0.8209 - val_loss: 3.9164 - val_box_loss: 2.7638 - val_focal_loss: 1.1527\n",
            "Epoch 7/200\n",
            "39/39 [==============================] - 89s 2s/step\n",
            "39/39 [==============================] - 89s 2s/step\n",
            "39/39 [==============================] - 145s 4s/step - loss: 3.5309 - box_loss: 2.7181 - focal_loss: 0.8128 - val_loss: 3.7416 - val_box_loss: 2.7387 - val_focal_loss: 1.0029\n",
            "Epoch 8/200\n",
            "38/39 [============================>.] - ETA: 0s - loss: 3.4971 - box_loss: 2.6894 - focal_loss: 0.8076"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6d18d90e53a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             validation_steps=val_steps)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m             validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     batch_size = self._validate_or_infer_batch_size(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mfit_distributed\u001b[0;34m(model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m    129\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     return training_arrays.fit_loop(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mexperimental_tpu_fit_loop\u001b[0;34m(model, dataset, epochs, verbose, callbacks, initial_epoch, steps_per_epoch, val_dataset, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    444\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m    447\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_distributed.py\u001b[0m in \u001b[0;36mexperimental_tpu_test_loop\u001b[0;34m(model, dataset, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0mdistributed_training_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_weights_to_distributed_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m   \u001b[0mdistributed_training_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m   callbacks = cbks.configure_callbacks(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/distribute/distributed_training_utils.py\u001b[0m in \u001b[0;36m_reset_metrics\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    990\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdistributed_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mfirst_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributed_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0mfirst_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_output_loss_metrics'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_loss_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \u001b[0;31m# Reset metrics on all the distributed (cloned) models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \"\"\"\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3069\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3071\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1341\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rr7Y2cVaBrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aff474bb-f7e5-4583-c2ec-28d299298a51"
      },
      "source": [
        "model.save_weights('test')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: From /job:worker/replica:0/task:0:\nFile system scheme '[local]' not implemented (file: 'test_temp_e4d1c00d49fe401d945767d05b93c545')\n\t [[{{node SaveV2}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ef43cc1c92c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[1;32m   1329\u001b[0m              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n\u001b[1;32m   1330\u001b[0m             % (optimizer,))\n\u001b[0;32m-> 1331\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m       \u001b[0;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: From /job:worker/replica:0/task:0:\nFile system scheme '[local]' not implemented (file: 'test_temp_e4d1c00d49fe401d945767d05b93c545')\n\t [[node SaveV2 (defined at <ipython-input-6-ef43cc1c92c6>:1) ]]\n\nOriginal stack trace for 'SaveV2':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-ef43cc1c92c6>\", line 1, in <module>\n    model.save_weights('test')\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\", line 1331, in save_weights\n    self._trackable_saver.save(filepath, session=session)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\", line 1106, in save\n    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\", line 1054, in _save_cached_when_graph_building\n    save_op = saver.save(file_prefix)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\", line 230, in save\n    sharded_saves.append(saver.save(shard_prefix))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\", line 72, in save\n    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 1946, in save_v2\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGw6iodcjb-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}