{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.0.0-rc0\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "print('TensorFlow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found training 70000 images\n",
      "Found training 70000 labels\n",
      "Found validation 10000 images\n",
      "Found validation 10000 labels\n"
     ]
    }
   ],
   "source": [
    "train_image_paths = sorted(\n",
    "    glob('../../bdd/bdd100k/images/100k/train/*'))\n",
    "train_label_paths = sorted(\n",
    "    glob('../../bdd/bdd100k/labels/100k/train/*'))\n",
    "validation_image_paths = sorted(\n",
    "    glob('../../bdd/bdd100k/images/100k/val/*'))\n",
    "validation_label_paths = sorted(\n",
    "    glob('../../bdd/bdd100k/labels/100k/val/*'))\n",
    "\n",
    "print('Found training {} images'.format(len(train_image_paths)))\n",
    "print('Found training {} labels'.format(len(train_label_paths)))\n",
    "print('Found validation {} images'.format(len(validation_image_paths)))\n",
    "print('Found validation {} labels'.format(len(validation_label_paths)))\n",
    "\n",
    "class_map = {value: idx for idx, value in enumerate(['bus',\n",
    "                                                     'traffic light',\n",
    "                                                     'traffic sign',\n",
    "                                                     'person',\n",
    "                                                     'bike',\n",
    "                                                     'truck',\n",
    "                                                     'motor',\n",
    "                                                     'car',\n",
    "                                                     'train',\n",
    "                                                     'rider'])}\n",
    "for image, label in zip(train_image_paths, train_label_paths):\n",
    "    assert image.split(\n",
    "        '/')[-1].split('.')[0] == label.split('/')[-1].split('.')[0]\n",
    "for image, label in zip(validation_image_paths, validation_label_paths):\n",
    "    assert image.split(\n",
    "        '/')[-1].split('.')[0] == label.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbe0618c3334778a75495d8edc5315e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=70000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a21d62996da4ae0a0c45ae792bce67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_label(label_path, class_map):\n",
    "    with open(label_path, 'r') as f:\n",
    "        temp = json.load(f)\n",
    "    bbox = []\n",
    "    class_ids = []\n",
    "    for obj in temp['frames'][0]['objects']:\n",
    "        if 'box2d' in obj:\n",
    "            x1 = obj['box2d']['x1']\n",
    "            y1 = obj['box2d']['y1']\n",
    "            x2 = obj['box2d']['x2']\n",
    "            y2 = obj['box2d']['y2']\n",
    "            bbox.append(np.array([x1, y1, x2, y2]))\n",
    "            class_ids.append(class_map[obj['category']])\n",
    "    bbox = np.array(bbox, dtype=np.float32)\n",
    "    class_ids = np.array(class_ids, dtype=np.float32)[..., None]\n",
    "    return np.concatenate([bbox, class_ids], axis=-1)\n",
    "\n",
    "train_labels = []\n",
    "validation_labels = []\n",
    "\n",
    "for path in tqdm_notebook(train_label_paths):\n",
    "    train_labels.append(get_label(path, class_map))\n",
    "for path in tqdm_notebook(validation_label_paths):\n",
    "    validation_labels.append(get_label(path, class_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_map)\n",
    "input_shape = 512\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 2\n",
    "training_steps = len(train_image_paths) // BATCH_SIZE\n",
    "validation_steps = len(validation_image_paths) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_image(image_path, input_shape=None):\n",
    "    H = W = input_shape\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, size=[H, W])\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_data(input_shape=None):\n",
    "    def load_data(image_path, label):\n",
    "        images = get_image(image_path, input_shape=input_shape)\n",
    "        targets = encode_targets(label, input_shape=input_shape)\n",
    "        # To-do : transform bbox to account image resizing, add random_flip \n",
    "        return images, targets\n",
    "    return load_data\n",
    "\n",
    "@tf.function()\n",
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1 = tf.cast(boxes1, dtype=tf.float32)\n",
    "    boxes2 = tf.cast(boxes2, dtype=tf.float32)\n",
    "\n",
    "    boxes1_t = change_box_format(boxes1, return_format='x1y1x2y2')\n",
    "    boxes2_t = change_box_format(boxes2, return_format='x1y1x2y2')\n",
    "\n",
    "    lu = tf.maximum(boxes1_t[:, None, :2], boxes2_t[:, :2])  # ld ru ??\n",
    "    rd = tf.minimum(boxes1_t[:, None, 2:], boxes2_t[:, 2:])\n",
    "\n",
    "    intersection = tf.maximum(0.0, rd - lu)\n",
    "    inter_square = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "\n",
    "    square1 = boxes1[:, 2] * boxes1[:, 3]\n",
    "    square2 = boxes2[:, 2] * boxes2[:, 3]\n",
    "\n",
    "    union_square = tf.maximum(square1[:, None] + square2 - inter_square, 1e-10)\n",
    "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def change_box_format(boxes, return_format='xywh'):\n",
    "    boxes = tf.cast(boxes, dtype=tf.float32)\n",
    "    if return_format == 'xywh':\n",
    "        # x1 y1 x2 y2\n",
    "        # 0  1  2  3\n",
    "        return tf.stack([(boxes[..., 2] + boxes[..., 0]) / 2.0,\n",
    "                         (boxes[..., 3] + boxes[..., 1]) / 2.0,\n",
    "                         boxes[..., 2] - boxes[..., 0],\n",
    "                         boxes[..., 3] - boxes[..., 1]], axis=-1)\n",
    "    elif return_format == 'x1y1x2y2':\n",
    "        # x  y  w  h\n",
    "        # 0  1  2  3\n",
    "        return tf.stack([boxes[..., 0] - boxes[..., 2] / 2.0,\n",
    "                         boxes[..., 1] - boxes[..., 3] / 2.0,\n",
    "                         boxes[..., 0] + boxes[..., 2] / 2.0,\n",
    "                         boxes[..., 1] + boxes[..., 3] / 2.0], axis=-1)\n",
    "    return 'You should not be here'\n",
    "\n",
    "\n",
    "def compute_anchor_dimensions(ratios=[0.5, 1, 2],\n",
    "                              scales=[1, 1.25, 1.58],\n",
    "                              areas=[32 * 32, 64 * 64, 128 * 128, 256 * 256, 512 * 512]):\n",
    "    anchor_shapes = {'P{}'.format(i): [] for i in range(3, 8)}\n",
    "    for area in areas:\n",
    "        for ratio in ratios:\n",
    "            a_h = np.sqrt(area / ratio)\n",
    "            a_w = area / a_h\n",
    "            for scale in scales:\n",
    "                h = np.int32(scale * a_h)\n",
    "                w = np.int32(scale * a_w)\n",
    "                anchor_shapes['P{}'.format(\n",
    "                    int(np.log2(np.sqrt(area) // 4)))].append([w, h])\n",
    "        anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))] = np.array(\n",
    "            anchor_shapes['P{}'.format(int(np.log2(np.sqrt(area) // 4)))])\n",
    "    return anchor_shapes\n",
    "\n",
    "\n",
    "def get_anchors(input_shape=512, tensor=True):\n",
    "    anchor_dimensions = compute_anchor_dimensions()\n",
    "    anchors = []\n",
    "    for i in range(3, 8):\n",
    "        feature_name = 'P{}'.format(i)\n",
    "        stride = 2**i\n",
    "        feature_size = (input_shape) // stride\n",
    "\n",
    "        dims = anchor_dimensions[feature_name]\n",
    "        dims = dims[None, None, ...]\n",
    "        dims = np.tile(dims, reps=[feature_size, feature_size, 1, 1])\n",
    "\n",
    "        rx = (np.arange(feature_size) + 0.5) * (stride)\n",
    "        ry = (np.arange(feature_size) + 0.5) * (stride)\n",
    "        sx, sy = np.meshgrid(rx, ry)\n",
    "        cxy = np.stack([sx, sy], axis=-1)\n",
    "        cxy = cxy[:, :, None, :]\n",
    "        cxy = np.tile(cxy, reps=[1, 1, 9, 1])\n",
    "        anchors.append(np.reshape(\n",
    "            np.concatenate([cxy, dims], axis=-1), [-1, 4]))\n",
    "    anchors = np.concatenate(anchors, axis=0)\n",
    "    if tensor:\n",
    "        anchors = tf.constant(anchors, dtype=tf.float32)\n",
    "    return anchors\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def encode_targets(label, input_shape=None):\n",
    "    \"\"\"We use the assignment rule from RPN.\n",
    "        Faster RCNN box coder follows the coding schema described below:\n",
    "            ty = (y - ya) / ha\n",
    "            tx = (x - xa) / wa\n",
    "            th = log(h / ha)\n",
    "            tw = log(w / wa)\n",
    "        where x, y, w, h denote the box's center coordinates, width and height\n",
    "        respectively. Similarly, xa, ya, wa, ha denote the anchor's center\n",
    "        coordinates, width and height. tx, ty, tw and th denote the\n",
    "        anchor-encoded center, width and height respectively.\n",
    "        See http://arxiv.org/abs/1506.01497 for details.\n",
    "    \"\"\"\n",
    "    anchors = get_anchors(input_shape=input_shape, tensor=True)\n",
    "    gt_boxes = label[:, :4]\n",
    "    gt_boxes = change_box_format(gt_boxes, return_format='xywh')\n",
    "    gt_class_ids = label[:, 4]\n",
    "    ious = compute_iou(anchors, gt_boxes)\n",
    "\n",
    "    max_ious = tf.reduce_max(ious, axis=1)\n",
    "    max_ids = tf.argmax(ious, axis=1, output_type=tf.int32)\n",
    "\n",
    "    background_mask = max_ious > 0.5\n",
    "    ignore_mask = tf.logical_and(max_ious > 0.4, max_ious < 0.5)\n",
    "\n",
    "    selected_gt_boxes = tf.gather(gt_boxes, max_ids)\n",
    "    selected_gt_class_ids = 1. + tf.gather(gt_class_ids, max_ids)\n",
    "\n",
    "    \"\"\" set achors with iou < 0.5 to 0\n",
    "        set achors with iou iout > 0.4 && < 0.5 to -1\n",
    "    \"\"\"\n",
    "    selected_gt_class_ids = selected_gt_class_ids * \\\n",
    "        tf.cast(background_mask, dtype=tf.float32)\n",
    "    classification_targets = selected_gt_class_ids - \\\n",
    "        tf.cast(\n",
    "            ignore_mask, dtype=tf.float32)\n",
    "    regression_targets = tf.stack([\n",
    "        (selected_gt_boxes[:, 0] - anchors[:, 0]) / anchors[:, 2],\n",
    "        (selected_gt_boxes[:, 1] - anchors[:, 1]) / anchors[:, 3],\n",
    "        tf.math.log(selected_gt_boxes[:, 2] / anchors[:, 2]),\n",
    "        tf.math.log(selected_gt_boxes[:, 3] / anchors[:, 3])\n",
    "    ], axis=-1)\n",
    "    return (tf.cast(classification_targets, dtype=tf.int32),\n",
    "            regression_targets,\n",
    "            background_mask,\n",
    "            ignore_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_generator():\n",
    "    for i in range(len(train_image_paths)):\n",
    "        yield train_image_paths[i], train_labels[i]\n",
    "\n",
    "\n",
    "def validation_data_generator():\n",
    "    for i in range(len(validation_image_paths)):\n",
    "        yield validation_image_paths[i], validation_labels[i]\n",
    "\n",
    "\n",
    "def input_fn(training=True, context_id=None):\n",
    "    def train_input_fn():\n",
    "        train_dataset = tf.data.Dataset.from_generator(\n",
    "            train_data_generator, output_types=(tf.string, tf.float32))\n",
    "        train_dataset = train_dataset.shuffle(1024)\n",
    "        train_dataset = train_dataset.map(\n",
    "            load_data(input_shape), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "        train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        return train_dataset\n",
    "\n",
    "    def validation_input_fn():\n",
    "        validation_dataset = tf.data.Dataset.from_generator(\n",
    "            validation_data_generator, output_types=(tf.string, tf.float32))\n",
    "        validation_dataset = validation_dataset.map(\n",
    "            load_data(input_shape), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        validation_dataset = validation_dataset.batch(\n",
    "            BATCH_SIZE, drop_remainder=True)\n",
    "        validation_dataset = validation_dataset.prefetch(\n",
    "            tf.data.experimental.AUTOTUNE)\n",
    "        return validation_dataset\n",
    "    if training:\n",
    "        return train_input_fn\n",
    "    return validation_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(tf.keras.losses.Loss):\n",
    "    def __init__(self, n_classes=None):\n",
    "        self.smooth_l1 = tf.losses.Huber()\n",
    "        self.num_classes = n_classes\n",
    "\n",
    "    def focal_loss(self, y_true, y_pred, alpha=0.25, gamma=2):\n",
    "        y_true = tf.one_hot(y_true, depth=self.num_classes + 1)\n",
    "        y_true = y_true[:, 1:]\n",
    "        y_pred = tf.sigmoid(y_pred)\n",
    "\n",
    "        ce = tf.losses.binary_crossentropy(y_true, y_pred, from_logits=False)\n",
    "        at = alpha * y_true + (1 - y_true) * (1 - alpha)\n",
    "        pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        loss = at * tf.pow(1 - pt, gamma) * tf.expand_dims(ce, axis=1)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        return loss\n",
    "\n",
    "    def call(self,\n",
    "             classification_targets,\n",
    "             classification_predictions,\n",
    "             regression_targets,\n",
    "             regression_predictions,\n",
    "             background_mask,\n",
    "             ignore_mask):\n",
    "        num_positive_detections = tf.maximum(tf.reduce_sum(\n",
    "            tf.cast(background_mask, dtype=tf.float32)), 1.0)\n",
    "        positive_classification_mask = tf.logical_not(ignore_mask)\n",
    "\n",
    "        regression_targets_positive = tf.boolean_mask(\n",
    "            regression_targets, background_mask)\n",
    "        regression_predictions_positive = tf.boolean_mask(\n",
    "            regression_predictions, background_mask)\n",
    "\n",
    "        classification_targets_positive = tf.boolean_mask(\n",
    "            classification_targets, positive_classification_mask)\n",
    "        classification_predictions_positive = tf.boolean_mask(\n",
    "            classification_predictions, positive_classification_mask)\n",
    "\n",
    "        Lreg = self.smooth_l1(regression_targets_positive,\n",
    "                              regression_predictions_positive)\n",
    "        Lcls = self.focal_loss(classification_targets_positive,\n",
    "                               classification_predictions_positive)\n",
    "        return Lreg / num_positive_detections, Lcls / num_positive_detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def conv_block(x,\n",
    "               n_filters,\n",
    "               size,\n",
    "               strides=1,\n",
    "               kernel_init='he_normal',\n",
    "               bias_init='zeros',\n",
    "               bn_activated=False):\n",
    "    x = tf.keras.layers.Conv2D(filters=n_filters,\n",
    "                               kernel_size=size,\n",
    "                               padding='same',\n",
    "                               strides=strides,\n",
    "                               kernel_initializer=kernel_init,\n",
    "                               bias_initializer=bias_init)(x)\n",
    "    if bn_activated:\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def Upsampling(tensor, scale=2):\n",
    "    dims = tensor.shape.as_list()[1:-1]\n",
    "    return tf.image.resize(tensor, size=[dims[0] * scale, dims[1] * scale])\n",
    "\n",
    "\n",
    "def build_classification_subnet(n_classes=100, n_anchors=9, p=0.01):\n",
    "    input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
    "    x = input_layer\n",
    "    for i in range(4):\n",
    "        x = conv_block(\n",
    "            x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    bias_init = -tf.math.log((1 - p) / p).numpy()\n",
    "    output_layer = tf.keras.layers.Conv2D(filters=n_classes * n_anchors,\n",
    "                                          kernel_size=3,\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "                                              0.0, 0.01),\n",
    "                                          bias_initializer=tf.keras.initializers.Constant(\n",
    "                                              value=bias_init),\n",
    "                                          activation=None)(x)\n",
    "    output_layer = tf.keras.layers.Reshape(\n",
    "        target_shape=[-1, n_classes])(output_layer)\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='classification_subnet')\n",
    "\n",
    "\n",
    "def build_regression_subnet(n_anchors=9):\n",
    "    input_layer = tf.keras.layers.Input(shape=[None, None, 256])\n",
    "    x = input_layer\n",
    "    for i in range(4):\n",
    "        x = conv_block(\n",
    "            x, 256, 3, kernel_init=tf.keras.initializers.RandomNormal(0.0, 0.01))\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    output_layer = tf.keras.layers.Conv2D(filters=4 * n_anchors,\n",
    "                                          kernel_size=3,\n",
    "                                          padding='same',\n",
    "                                          kernel_initializer=tf.keras.initializers.RandomNormal(\n",
    "                                              0.0, 0.01),\n",
    "                                          bias_initializer=tf.keras.initializers.zeros(),\n",
    "                                          activation=None)(x)\n",
    "    output_layer = tf.keras.layers.Reshape(target_shape=[-1, 4])(output_layer)\n",
    "    return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='regression_subnet')\n",
    "\n",
    "\n",
    "def RetinaNet(input_shape=None, n_classes=None):\n",
    "    H = W = input_shape\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        input_shape=[H, W, 3], weights='imagenet', include_top=False)\n",
    "\n",
    "    resnet_block_output_names = ['conv3_block4_out',\n",
    "                                 'conv4_block6_out', 'conv5_block3_out']\n",
    "    resnet_block_outputs = {'C{}'.format(idx + 3): base_model.get_layer(\n",
    "        layer).output for idx, layer in enumerate(resnet_block_output_names)}\n",
    "    resnet_block_outputs = {level: conv_block(\n",
    "        tensor, 256, 1) for level, tensor in resnet_block_outputs.items()}\n",
    "\n",
    "    P5 = resnet_block_outputs['C5']\n",
    "    P6 = conv_block(P5, 256, 3, strides=2)\n",
    "    P6_relu = tf.keras.layers.ReLU()(P6)\n",
    "    P7 = conv_block(P6_relu, 256, 3, strides=2)\n",
    "    M4 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2})(\n",
    "        P5), resnet_block_outputs['C4']])\n",
    "    M3 = tf.keras.layers.add([tf.keras.layers.Lambda(Upsampling, arguments={'scale': 2})(\n",
    "        M4), resnet_block_outputs['C3']])\n",
    "    P4 = conv_block(M4, 256, 3)\n",
    "    P3 = conv_block(M3, 256, 3)\n",
    "    pyrammid_features = [P7, P6, P5, P4, P3]\n",
    "\n",
    "    classification_subnet = build_classification_subnet(n_classes=n_classes)\n",
    "    regression_subnet = build_regression_subnet()\n",
    "\n",
    "    classification_outputs = [classification_subnet(\n",
    "        level) for level in pyrammid_features]\n",
    "    regression_outputs = [regression_subnet(\n",
    "        level) for level in pyrammid_features]\n",
    "\n",
    "    classification_head = tf.keras.layers.concatenate(\n",
    "        classification_outputs, axis=1, name='classification_head')\n",
    "    regression_head = tf.keras.layers.concatenate(\n",
    "        regression_outputs, axis=1, name='regression_head')\n",
    "\n",
    "    return tf.keras.Model(inputs=base_model.input, outputs=[\n",
    "        classification_head, regression_head],\n",
    "        name='RetinaNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RetinaNet(input_shape=input_shape, n_classes=n_classes)\n",
    "model.build([None, input_shape, input_shape, 3])\n",
    "loss_fn = Loss(n_classes=n_classes)\n",
    "optimizer = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=1e-4)\n",
    "\n",
    "model_dir = 'model_files/'\n",
    "checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint,\n",
    "                                                directory=model_dir,\n",
    "                                                max_to_keep=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(batch):\n",
    "    image, (classification_targets,\n",
    "            regression_targets,\n",
    "            background_mask,\n",
    "            ignore_mask) = batch\n",
    "    with tf.GradientTape() as tape:\n",
    "        regression_predictions, classification_predictions = model(\n",
    "            image, training=True)\n",
    "        Lreg, Lcls = loss_fn(classification_targets,\n",
    "                             classification_predictions,\n",
    "                             regression_targets,\n",
    "                             regression_predictions,\n",
    "                             background_mask,\n",
    "                             ignore_mask)\n",
    "        total_loss = Lreg + Lcls\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply(zip(gradients, model.trainable_variables))\n",
    "    loss_dict = {\n",
    "        'box_loss': Lreg,\n",
    "        'cls_loss': Lcls,\n",
    "        'total_loss': total_loss\n",
    "    }\n",
    "    return loss_dict\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def validation_step(batch):\n",
    "    image, (classification_targets,\n",
    "            regression_targets,\n",
    "            background_mask,\n",
    "            ignore_mask) = batch\n",
    "    regression_predictions, classification_predictions = model(\n",
    "        image, training=False)\n",
    "    Lreg, Lcls = loss_fn(classification_targets,\n",
    "                         classification_predictions,\n",
    "                         regression_targets,\n",
    "                         regression_predictions,\n",
    "                         background_mask,\n",
    "                         ignore_mask)\n",
    "    total_loss = Lreg + Lcls\n",
    "    loss_dict = {\n",
    "        'box_loss': Lreg,\n",
    "        'cls_loss': Lcls,\n",
    "        'total_loss': total_loss\n",
    "    }\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324744d193e149268669e647accc156d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c52eaad7112d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1015\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;34m\"IteratorGetNextSync\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m         \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(EPOCHS):\n",
    "    for batch in tqdm_notebook(input_fn(training=True)()):\n",
    "        pass\n",
    "    for batch in tqdm_notebook(input_fn(training=False)()):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(image, bbox_list):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    h, w = image.shape.as_list()[:2]\n",
    "    bboxes = tf.cast(tf.stack([\n",
    "        bbox_list[:, 1] / h, bbox_list[:, 0] /\n",
    "        w, bbox_list[:, 3] / h, bbox_list[:, 2] / w\n",
    "    ], axis=-1), dtype=tf.float32)\n",
    "    # To do, set colors for each class\n",
    "    colors = tf.random.uniform(maxval=1, shape=[bbox_list.shape[0], 3])\n",
    "    return tf.image.draw_bounding_boxes(image[None, ...],\n",
    "                                        bboxes[None, ...], colors)[0, ...]\n",
    "\n",
    "def decode_targets(classification_outputs, regression_outputs, input_shape=None, classification_threshold=0.05, nms_threshold=0.5):\n",
    "    anchors = get_anchors(input_shape=input_shape, tensor=True)\n",
    "    confidence_scores = tf.reduce_max(\n",
    "        tf.sigmoid(classification_outputs), axis=-1)\n",
    "    class_ids = tf.argmax(classification_outputs, axis=-1)\n",
    "    boxes = tf.concat([(regression_outputs[:, :2] * anchors[:, 2:] + anchors[:, :2]),\n",
    "                       tf.math.exp(regression_outputs[:, 2:]) * anchors[:, 2:]\n",
    "                       ], axis=-1)\n",
    "    non_zero_class_mask = tf.where(class_ids > 0)[:, 0]\n",
    "    non_zero_class_ids = tf.gather(class_ids, non_zero_class_mask)\n",
    "    non_zero_class_confidence_scores = tf.gather(\n",
    "        confidence_scores, non_zero_class_mask)\n",
    "    non_zero_class_bboxes = tf.gather(boxes, non_zero_class_mask)\n",
    "\n",
    "    nms_indices = tf.image.non_max_suppression(non_zero_class_bboxes,\n",
    "                                               non_zero_class_confidence_scores,\n",
    "                                               iou_threshold=nms_threshold,\n",
    "                                               max_output_size=200)\n",
    "\n",
    "    final_class_ids = tf.gather(non_zero_class_ids, nms_indices)\n",
    "    final_scores = tf.gather(non_zero_class_confidence_scores, nms_indices)\n",
    "    final_boxes_ = tf.gather(non_zero_class_bboxes, nms_indices)\n",
    "    final_boxes = tf.cast(change_box_format(final_boxes_, return_format='x1y1x2y2'),\n",
    "                          dtype=tf.int32)\n",
    "    return final_boxes, final_class_ids, final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
