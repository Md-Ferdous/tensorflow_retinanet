{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.0.0-rc0\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage.io import imread, imsave\n",
    "from model.retinanet import RetinaNet\n",
    "from utils import get_anchors, decode_targets, draw_bboxes, get_image\n",
    "\n",
    "print('TensorFlow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found training 70000 images\n",
      "Found training 70000 labels\n",
      "Found validation 10000 images\n",
      "Found validation 10000 labels\n"
     ]
    }
   ],
   "source": [
    "train_image_paths = sorted(\n",
    "    glob('../../bdd/bdd100k/images/100k/train/*'))\n",
    "train_label_paths = sorted(\n",
    "    glob('../../bdd/bdd100k/labels/100k/train/*'))\n",
    "validation_image_paths = sorted(\n",
    "    glob('../../bdd/bdd100k/images/100k/val/*'))\n",
    "validation_label_paths = sorted(\n",
    "    glob('../../bdd/bdd100k/labels/100k/val/*'))\n",
    "\n",
    "print('Found training {} images'.format(len(train_image_paths)))\n",
    "print('Found training {} labels'.format(len(train_label_paths)))\n",
    "print('Found validation {} images'.format(len(validation_image_paths)))\n",
    "print('Found validation {} labels'.format(len(validation_label_paths)))\n",
    "\n",
    "class_map = {value: idx for idx, value in enumerate(['bus',\n",
    "                                                     'traffic light',\n",
    "                                                     'traffic sign',\n",
    "                                                     'person',\n",
    "                                                     'bike',\n",
    "                                                     'truck',\n",
    "                                                     'motor',\n",
    "                                                     'car',\n",
    "                                                     'train',\n",
    "                                                     'rider'])}\n",
    "for image, label in zip(train_image_paths, train_label_paths):\n",
    "    assert image.split(\n",
    "        '/')[-1].split('.')[0] == label.split('/')[-1].split('.')[0]\n",
    "for image, label in zip(validation_image_paths, validation_label_paths):\n",
    "    assert image.split(\n",
    "        '/')[-1].split('.')[0] == label.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=5>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t = tf.Variable(0)\n",
    "t.assign_add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_map)\n",
    "input_shape = 512\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 2\n",
    "training_steps = len(train_image_paths) // BATCH_SIZE\n",
    "validation_steps = len(validation_image_paths) // BATCH_SIZE\n",
    "\n",
    "model = RetinaNet(input_shape=input_shape, n_classes=n_classes)\n",
    "model.build([None, input_shape, input_shape, 3])\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "model_dir = 'model_files/'\n",
    "checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint,\n",
    "                                                directory=model_dir,\n",
    "                                                max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = checkpoint.restore('model_files/ckpt-9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=40748, shape=(2, 4), dtype=int32, numpy=\n",
       " array([[  9, 200, 141, 364],\n",
       "        [  1, 218,  88, 378]], dtype=int32)>,\n",
       " <tf.Tensor: id=40743, shape=(2,), dtype=int64, numpy=array([7, 7])>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = get_image(input_shape=512, image_path=train_image_paths[110])[None, ...]\n",
    "c_preds, r_preds = model(image)\n",
    "b, c, s, _ = decode_targets(c_preds[0], r_preds[0], classification_threshold=.2, nms_threshold=0.5)\n",
    "img = (image[0] + tf.constant([103.939, 116.779, 123.68]))[:, :, ::-1]\n",
    "img = draw_bboxes(img, b).numpy()\n",
    "imsave('inference.png', img)\n",
    "b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_files/ckpt-8'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_manager.latest_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
